{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, \"../\")\n",
    "from typing import List\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import deba\n",
    "\n",
    "from lib.dropbox import sync_local_to_dropbox\n",
    "from lib.pdf import subset_pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes/export/src/subset-pdfs.R\n",
    "\n",
    "\n",
    "def create_pdf_index(hrgs: pd.DataFrame, meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    meta = meta.loc[\n",
    "        meta.filetype.isin([\"word\", \"pdf\"]), [\"fileid\", \"filepath\", \"filetype\"]\n",
    "    ]\n",
    "    driver = (\n",
    "        hrgs.loc[\n",
    "            hrgs.hrg_acc_uid.notna() | hrgs.hrg_type.isin([\"police\", \"unknown\"]),\n",
    "            [\"docid\", \"fileid\", \"doc_pg_from\", \"doc_pg_to\"],\n",
    "        ]\n",
    "        .drop_duplicates()\n",
    "        .merge(meta, on=\"fileid\", how=\"left\")\n",
    "    )\n",
    "    driver.loc[:, \"ext\"] = driver.filepath.str.replace(\n",
    "        r\".+\\.(\\w+)$\", r\"\\1\", regex=True\n",
    "    ).str.lower()\n",
    "    driver.loc[:, \"pdfname\"] = driver.apply(\n",
    "        lambda row: os.path.join(\"pdfs\", \"%s.%s\" % (row.docid, row.ext)),\n",
    "        result_type=\"reduce\",\n",
    "    )\n",
    "    driver.loc[:, \"page_count\"] = driver.apply(\n",
    "        lambda row: row.doc_pg_to - row.doc_pg_from, result_type=\"reduce\"\n",
    "    )\n",
    "    for _, row in driver.iterrows():\n",
    "        new_filepath = os.path.join(MINUTES_LOCAL_ROOT, row.pdfname)\n",
    "        if row.filetype == \"word\":\n",
    "            shutil.copy(row.filepath, new_filepath)\n",
    "        else:\n",
    "            subset_pdf(row.filepath, new_filepath, row.doc_pg_from, row.doc_pg_to)\n",
    "    return driver[[\"docid\", \"page_count\", \"pdfname\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes/export/src/docs2txt.R\n",
    "\n",
    "\n",
    "def create_txt_index(docs: pd.DataFrame)->pd.DataFrame:\n",
    "    newlines_re = re.compile(r\"(?:\\n\\s*){3,}\")\n",
    "\n",
    "    def combine_texts(rows: pd.DataFrame) -> pd.Series:\n",
    "        first_row = rows.iloc[0].copy()\n",
    "        first_row.loc[\"txtname\"] = os.path.join(\"txt\", \"%s.txt\" % first_row.docid)\n",
    "        with open(os.path.join(MINUTES_LOCAL_ROOT, first_row.loc[\"txtname\"]), \"w\") as f:\n",
    "            f.write(newlines_re.sub(rows.text.str.cat(sep=\"\\n\"), \"\\n\\n\").strip())\n",
    "        return first_row\n",
    "\n",
    "    return (\n",
    "        docs.sort_values(by=[\"docid\", \"fileid\", \"pageno\"])\n",
    "        .groupby(\"docid\")\n",
    "        .agg(combine_texts)[[\"docid\", \"txtname\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes/export/src/dropbox-up.R\n",
    "\n",
    "MINUTES_DB_ROOT = \"/PPACT/meeting-minutes-extraction/export\"\n",
    "MINUTES_LOCAL_ROOT = deba.data(\"minutes_documents\")\n",
    "\n",
    "\n",
    "def synced_to_dropbox(df: pd.DataFrame, file_paths: List[str]) -> pd.DataFrame:\n",
    "    return df.join(\n",
    "        pd.DataFrame(\n",
    "            sync_local_to_dropbox(\n",
    "                MINUTES_LOCAL_ROOT, MINUTES_DB_ROOT, file_paths, dry_run=True\n",
    "            ),\n",
    "            columns=[\"db_path\", \"db_id\", \"db_content_hash\"],\n",
    "            index=df.index,\n",
    "        )\n",
    "    ).set_index(\"docid\")\n",
    "\n",
    "\n",
    "def combine_pdfs_txts(pdfs: pd.DataFrame, txts: pd.DataFrame) -> pd.DataFrame:\n",
    "    return synced_to_dropbox(pdfs, pdfs.pdfname.tolist()).join(\n",
    "        synced_to_dropbox(txts, txts.txtname.tolist()),\n",
    "        how=\"inner\",\n",
    "        lsuffix=\"pdf_\",\n",
    "        rsuffix=\"txt_\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes/export/src/make-output.R\n",
    "\n",
    "\n",
    "def create_hearings(hrg: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = hrg\n",
    "    df.loc[:, \"hrg_text\"] = df.hrg_head.str.cat(df.hrg_text, sep=\"\\n\")\n",
    "\n",
    "    def create_title(row: pd.Series) -> str:\n",
    "        return \"Appeal hearing: {hrg_accused} on {date}\".format(\n",
    "            {\n",
    "                \"hrg_accused\": \"(unknown)\"\n",
    "                if pd.isna(row[\"hrg_accused\"])\n",
    "                else row[\"hrg_accused\"],\n",
    "                \"date\": \"(unknown)\"\n",
    "                if (pd.isna(row.year) or pd.isna(row.month) or pd.isna(row.day))\n",
    "                else \"-\".join(row.year, row.month, row.day),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df.loc[:, \"title\"] = df.apply(create_title, result_type=\"reduce\")\n",
    "    return (\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"mtg_year\": \"year\",\n",
    "                \"mtg_month\": \"month\",\n",
    "                \"mtg_day\": \"day\",\n",
    "                \"mtg_dt_source\": \"dt_source\",\n",
    "                \"hrgno\": \"hrg_no\",\n",
    "                \"hrg_accused\": \"accused\",\n",
    "                \"hrg_acc_uid\": \"matched_uid\",\n",
    "            }\n",
    "        )\n",
    "        .loc[\n",
    "            df.hrg_type != \"fire\",\n",
    "            [\n",
    "                \"docid\",\n",
    "                \"hrg_type\",\n",
    "                \"year\",\n",
    "                \"month\",\n",
    "                \"day\",\n",
    "                \"dt_source\",\n",
    "                \"hrg_no\",\n",
    "                \"accused\",\n",
    "                \"matched_uid\",\n",
    "                \"hrg_text\",\n",
    "                \"title\",\n",
    "                \"agency\",\n",
    "            ],\n",
    "        ]\n",
    "        .set_index(\"docid\", drop=False)\n",
    "    )\n",
    "\n",
    "\n",
    "def create_output(ind: pd.DataFrame, hearings: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = ind.join(hearings, how=\"inner\")\n",
    "    return df.loc[df.matched_uid.notna() | df.agency.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c95fe248860bd69136fd5934ca42b0656bc63db691883986ab38f5f0d896be5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
