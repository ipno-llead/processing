{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from top2vec import Top2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "# import umap.umap_ as umap\n",
    "# import umap.plot\n",
    "nltk.download(\"stopwords\")\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import gensim\n",
    "import gensim.corpora as corpora \n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_csv(\"../data/training_data/complaint_classification_labeled_data_1_31_2023.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows_with_multiple_labels(df):\n",
    "    df.loc[:, \"label\"] = (df.label.str.lower()\n",
    "                                  .str.strip()\n",
    "                                  .str.replace(r\"#\", \"/\", regex=False)\n",
    "                                  .str.replace(r\"internal misconduct\\/administrative infraction\",\n",
    "                                               \"internal misconduct; administrative infraction\", regex=True)\n",
    "    )\n",
    "    df = (\n",
    "        df.drop(\"label\", axis=1)\n",
    "        .join(\n",
    "            df[\"label\"]\n",
    "            .str.split(\"/\", expand=True)\n",
    "            .stack()\n",
    "            .reset_index(level=1, drop=True)\n",
    "            .rename(\"label\"),\n",
    "            how=\"outer\",\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pipe(split_rows_with_multiple_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(df):\n",
    "    dfa = df\n",
    "    dfa.loc[:, \"target\"] = (df.label.str.lower()\n",
    "                                    .str.strip()\n",
    "                                    .str.replace(r\"internal misconduct; administrative infraction\", \"\", regex=False)\n",
    "    )\n",
    "    dfa = dfa[~((dfa.target.fillna(\"\") == \"\"))]\n",
    "    dfa.loc[:, \"target\"] = dfa.target.str.replace(r\"(.+)\", \"0\", regex=True)\n",
    "\n",
    "    extract_targets = df.label.str.lower().str.strip().str.extract(r\"(internal misconduct; administrative infraction)\")\n",
    "\n",
    "    df.loc[:, \"target\"] = extract_targets[0].str.replace(r\"(.+)\", \"1\", regex=True)\n",
    "    df = df[~((df.target.fillna(\"\") == \"\"))]\n",
    "\n",
    "    df = pd.concat([df, dfa], axis=0)\n",
    "    df = df.rename(columns={\"text\": \"allegation_desc\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pipe(extract_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    training_data, test_data = train_test_split(df, test_size=0.3)\n",
    "    return training_data, test_data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data, og_df = split_data(df)\n",
    "\n",
    "training_data.to_csv(\"training_data/training_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    915\n",
       "1    165\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    405\n",
       "1     58\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### top2vec ##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df):\n",
    "    # unique = [x for x in df[\"allegation_topic_uid\"]]\n",
    "    df = [x for x in df[\"allegation_desc\"]]\n",
    "\n",
    "    model = Top2Vec(\n",
    "        df,\n",
    "        ngram_vocab=True,\n",
    "        speed=\"deep-learn\",\n",
    "        use_embedding_model_tokenizer=True,\n",
    "        min_count=5,\n",
    "        # document_ids=unique\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    top2vec = create_model(og_df)\n",
    "    return top2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 14:17:18,097 - top2vec - INFO - Pre-processing documents for training\n",
      "2023-02-01 14:17:18,343 - top2vec - INFO - Creating joint document/word embedding\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Desktop\\launch\\processing\\classification\\topic_models.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model()\n",
      "\u001b[1;32mc:\\Users\\PC\\Desktop\\launch\\processing\\classification\\topic_models.ipynb Cell 15\u001b[0m in \u001b[0;36mmodel\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     top2vec \u001b[39m=\u001b[39m create_model(og_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m top2vec\n",
      "\u001b[1;32mc:\\Users\\PC\\Desktop\\launch\\processing\\classification\\topic_models.ipynb Cell 15\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_model\u001b[39m(df):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# unique = [x for x in df[\"allegation_topic_uid\"]]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     df \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df[\u001b[39m\"\u001b[39m\u001b[39mallegation_desc\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model \u001b[39m=\u001b[39m Top2Vec(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         df,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         ngram_vocab\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         speed\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdeep-learn\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         use_embedding_model_tokenizer\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         min_count\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m# document_ids=unique\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PC/Desktop/launch/processing/classification/topic_models.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\top2vec\\Top2Vec.py:526\u001b[0m, in \u001b[0;36mTop2Vec.__init__\u001b[1;34m(self, documents, min_count, ngram_vocab, ngram_vocab_args, embedding_model, embedding_model_path, embedding_batch_size, split_documents, document_chunker, chunk_length, max_num_chunks, chunk_overlap_ratio, chunk_len_coverage_ratio, sentencizer, speed, use_corpus_file, document_ids, keep_documents, workers, tokenizer, use_embedding_model_tokenizer, umap_args, hdbscan_args, verbose)\u001b[0m\n\u001b[0;32m    524\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mCreating joint document/word embedding\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    525\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdoc2vec\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 526\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m Doc2Vec(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdoc2vec_args)\n\u001b[0;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mget_normed_vectors()\n\u001b[0;32m    529\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_indexes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mkey_to_index\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\doc2vec.py:296\u001b[0m, in \u001b[0;36mDoc2Vec.__init__\u001b[1;34m(self, documents, corpus_file, vector_size, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, dv, dv_mapfile, comment, trim_rule, callbacks, window, epochs, shrink_windows, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m# EXPERIMENTAL lockf feature; create minimal no-op lockf arrays (1 element of 1.0)\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m# advanced users should directly resize/adjust as desired after any vocab growth\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdv\u001b[39m.\u001b[39mvectors_lockf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mREAL)  \u001b[39m# 0.0 values suppress word-backprop-updates; 1.0 allows\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m \u001b[39msuper\u001b[39m(Doc2Vec, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    297\u001b[0m     sentences\u001b[39m=\u001b[39mcorpus_iterable,\n\u001b[0;32m    298\u001b[0m     corpus_file\u001b[39m=\u001b[39mcorpus_file,\n\u001b[0;32m    299\u001b[0m     vector_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvector_size,\n\u001b[0;32m    300\u001b[0m     sg\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m dm) \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m    301\u001b[0m     null_word\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdm_concat,\n\u001b[0;32m    302\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m    303\u001b[0m     window\u001b[39m=\u001b[39mwindow,\n\u001b[0;32m    304\u001b[0m     epochs\u001b[39m=\u001b[39mepochs,\n\u001b[0;32m    305\u001b[0m     shrink_windows\u001b[39m=\u001b[39mshrink_windows,\n\u001b[0;32m    306\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    307\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\word2vec.py:427\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, passes\u001b[39m=\u001b[39m(epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m    426\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_vocab(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, trim_rule\u001b[39m=\u001b[39mtrim_rule)\n\u001b[1;32m--> 427\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m    428\u001b[0m         corpus_iterable\u001b[39m=\u001b[39;49mcorpus_iterable, corpus_file\u001b[39m=\u001b[39;49mcorpus_file, total_examples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_count,\n\u001b[0;32m    429\u001b[0m         total_words\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_total_words, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, start_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m    430\u001b[0m         end_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_alpha, compute_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m    431\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     \u001b[39mif\u001b[39;00m trim_rule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39moffsets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m offsets\n\u001b[0;32m    514\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstart_doctags\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m start_doctags\n\u001b[1;32m--> 516\u001b[0m \u001b[39msuper\u001b[39m(Doc2Vec, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrain(\n\u001b[0;32m    517\u001b[0m     corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file,\n\u001b[0;32m    518\u001b[0m     total_examples\u001b[39m=\u001b[39mtotal_examples, total_words\u001b[39m=\u001b[39mtotal_words,\n\u001b[0;32m    519\u001b[0m     epochs\u001b[39m=\u001b[39mepochs, start_alpha\u001b[39m=\u001b[39mstart_alpha, end_alpha\u001b[39m=\u001b[39mend_alpha, word_count\u001b[39m=\u001b[39mword_count,\n\u001b[0;32m    520\u001b[0m     queue_factor\u001b[39m=\u001b[39mqueue_factor, report_delay\u001b[39m=\u001b[39mreport_delay, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\word2vec.py:1070\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     callback\u001b[39m.\u001b[39mon_epoch_begin(\u001b[39mself\u001b[39m)\n\u001b[0;32m   1069\u001b[0m \u001b[39mif\u001b[39;00m corpus_iterable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1070\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch(\n\u001b[0;32m   1071\u001b[0m         corpus_iterable, cur_epoch\u001b[39m=\u001b[39mcur_epoch, total_examples\u001b[39m=\u001b[39mtotal_examples,\n\u001b[0;32m   1072\u001b[0m         total_words\u001b[39m=\u001b[39mtotal_words, queue_factor\u001b[39m=\u001b[39mqueue_factor, report_delay\u001b[39m=\u001b[39mreport_delay,\n\u001b[0;32m   1073\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1074\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch_corpusfile(\n\u001b[0;32m   1076\u001b[0m         corpus_file, cur_epoch\u001b[39m=\u001b[39mcur_epoch, total_examples\u001b[39m=\u001b[39mtotal_examples, total_words\u001b[39m=\u001b[39mtotal_words,\n\u001b[0;32m   1077\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\word2vec.py:1431\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     thread\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m-> 1431\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_epoch_progress(\n\u001b[0;32m   1432\u001b[0m     progress_queue, job_queue, cur_epoch\u001b[39m=\u001b[39;49mcur_epoch, total_examples\u001b[39m=\u001b[39;49mtotal_examples,\n\u001b[0;32m   1433\u001b[0m     total_words\u001b[39m=\u001b[39;49mtotal_words, report_delay\u001b[39m=\u001b[39;49mreport_delay, is_corpus_file_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1434\u001b[0m )\n\u001b[0;32m   1436\u001b[0m \u001b[39mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\word2vec.py:1286\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m   1283\u001b[0m unfinished_worker_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\n\u001b[0;32m   1285\u001b[0m \u001b[39mwhile\u001b[39;00m unfinished_worker_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1286\u001b[0m     report \u001b[39m=\u001b[39m progress_queue\u001b[39m.\u001b[39;49mget()  \u001b[39m# blocks if workers too slow\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m     \u001b[39mif\u001b[39;00m report \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# a thread reporting that it finished\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m         unfinished_worker_count \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[0;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(model.get_topic_sizes()) > 1:\n",
    "#     topic_words, word_scores, topic_nums = model.get_topics()\n",
    "#     for words, scores, num in zip(topic_words, word_scores, topic_nums):\n",
    "#         print(num)\n",
    "#         print(f\"Words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_sizes, top_nums = model.get_topic_sizes()\n",
    "# print(topic_sizes)\n",
    "# print(top_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=1, num_docs=10)\n",
    "\n",
    "# for doc, score, doc_id in list(zip(documents, document_scores, document_ids)):\n",
    "#     print(f\"Document: {doc_id}, Score: {score}\")\n",
    "#     print(\"--------------------\")\n",
    "#     print(doc)\n",
    "#     print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=0, num_docs=20)\n",
    "\n",
    "# ents = {(doc, score) for doc, score in list(zip(documents, document_scores))}\n",
    "# df = pd.DataFrame(ents, columns=[\"allegation_desc\", \"score\"])\n",
    "# print(df)\n",
    "# df.loc[:, \"topic\"] = \"9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/top2vec_train_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.generate_topic_wordcloud(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.topic_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_words, word_scores, topic_nums = model.get_topics(0)\n",
    "# for words, scores, nums in zip(topic_words, word_scores, topic_nums):\n",
    "#   print(\"Topic Number: \",nums)\n",
    "#   print(f\"Words: {words}\")\n",
    "#   print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"inmate\"], num_topics=0)\n",
    "# for word, w_score, topic, t_score in list(zip(topic_words, word_scores, topic_scores, topic_nums)):\n",
    "#     print(f\"Word: \\n{word}\")\n",
    "#     print(\"--------------------\")\n",
    "#     print(f\"Word Score \\n{w_score}\")\n",
    "#     print(\"--------------------\")\n",
    "#     print(f\"Topic Score: \\n{topic}\")\n",
    "#     print(\"--------------------\")\n",
    "#     print (f\"Topic # \\n{t_score}\")\n",
    "#     print(\"--------END---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Top2Vec.load(\"models/noso\")\n",
    "\n",
    "# umap_args = {\n",
    "#     \"n_neighbors\": 15,\n",
    "#     \"n_components\": 2, # 5 -> 2 for plotting \n",
    "#     \"metric\": \"cosine\",\n",
    "# }\n",
    "# umap_model = umap.UMAP(**umap_args).fit(model.topic_vectors)\n",
    "# umap.plot.points(umap_model, labels=model.doc_top_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ bertopic #################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = og_df.allegation_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = json.loads(docs.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=True)\n",
    "embeddings = np.array(embeddings)\n",
    "embeddings = pd.DataFrame(embeddings).to_csv(\"vecs/bert_train_vecs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\", vectorizer_model=vectorizer_model, diversity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"models/bert_train_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>364</td>\n",
       "      <td>-1_the_her_complainant_was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0_unprofessional_complainant_the_stated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>1_failed_court_to_appear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>2_camera_worn_body_activate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>3_inmate_inmates_dorm_sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>4_bwc_activate_cew_uof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>5_inmate_observed_food_giving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>6_late_reported_duty_minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>7_the_his_he_ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>8_did_not_write_report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>9_imate_accused_completing_inspections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>10_failing_domestic_questions_accused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>11_force_unauthorized_using_stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>12_accident_other_driver_citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>13_nopd_barricade_vehicle_the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>14_falsely_arrested_james_falsifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>15_lunch_so_instructed_assignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>16_failing_supervisor_subordinates_accused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>17_arresting_order_child_demeaned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>18_summons_property_warrant_sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>19_2018_allegation_professionalism_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>20_pod_found_handgun_seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>21_failed_system_facility_oder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22_report_me_failed_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>23_neglect_duty_of_public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>24_medical_inmate_staff_inmates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>25_leaving_area_1600_reynolds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>26_arrested_unattended_university_room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>27_rank_log_failed_keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>28_touched_technician_help_her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>29_altercation_verbal_engaged_worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>30_assignment_inclement_weather_hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>31_uof_complete_36_failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>32_sleeping_duty_observed_on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>33_break_extended_hours_taking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>34_patrol_patrols_security_opso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>35_cause_no_states_taken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>36_parking_windows_he_vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>37_2021_reporting_entertainment_venue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>38_training_class_mandatory_failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>39_traffic_stopped_stop_violation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                        Name\n",
       "0      -1    364                  -1_the_her_complainant_was\n",
       "1       0    135     0_unprofessional_complainant_the_stated\n",
       "2       1    111                    1_failed_court_to_appear\n",
       "3       2     64                 2_camera_worn_body_activate\n",
       "4       3     58                  3_inmate_inmates_dorm_sick\n",
       "5       4     42                      4_bwc_activate_cew_uof\n",
       "6       5     42               5_inmate_observed_food_giving\n",
       "7       6     38                6_late_reported_duty_minutes\n",
       "8       7     34                             7_the_his_he_ex\n",
       "9       8     34                      8_did_not_write_report\n",
       "10      9     32      9_imate_accused_completing_inspections\n",
       "11     10     32       10_failing_domestic_questions_accused\n",
       "12     11     31            11_force_unauthorized_using_stop\n",
       "13     12     29           12_accident_other_driver_citation\n",
       "14     13     29               13_nopd_barricade_vehicle_the\n",
       "15     14     28        14_falsely_arrested_james_falsifying\n",
       "16     15     26           15_lunch_so_instructed_assignment\n",
       "17     16     26  16_failing_supervisor_subordinates_accused\n",
       "18     17     25           17_arresting_order_child_demeaned\n",
       "19     18     25          18_summons_property_warrant_sister\n",
       "20     19     24       19_2018_allegation_professionalism_of\n",
       "21     20     24                   20_pod_found_handgun_seat\n",
       "22     21     23              21_failed_system_facility_oder\n",
       "23     22     22                      22_report_me_failed_to\n",
       "24     23     22                   23_neglect_duty_of_public\n",
       "25     24     22             24_medical_inmate_staff_inmates\n",
       "26     25     19               25_leaving_area_1600_reynolds\n",
       "27     26     19      26_arrested_unattended_university_room\n",
       "28     27     15                     27_rank_log_failed_keys\n",
       "29     28     15              28_touched_technician_help_her\n",
       "30     29     14        29_altercation_verbal_engaged_worker\n",
       "31     30     13       30_assignment_inclement_weather_hours\n",
       "32     31     13                   31_uof_complete_36_failed\n",
       "33     32     13                32_sleeping_duty_observed_on\n",
       "34     33     12              33_break_extended_hours_taking\n",
       "35     34     12             34_patrol_patrols_security_opso\n",
       "36     35     12                    35_cause_no_states_taken\n",
       "37     36     12               36_parking_windows_he_vehicle\n",
       "38     37     11       37_2021_reporting_entertainment_venue\n",
       "39     38     11          38_training_class_mandatory_failed\n",
       "40     39     10           39_traffic_stopped_stop_violation"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inmate', 0.07901585088530677),\n",
       " ('inmates', 0.06516692049177385),\n",
       " ('dorm', 0.048291933678696504),\n",
       " ('sick', 0.046680020022922694),\n",
       " ('cell', 0.04654780035126704),\n",
       " ('observed', 0.04603910810061461),\n",
       " ('allowed', 0.044026122844746725),\n",
       " ('out', 0.04048334668066706),\n",
       " ('on', 0.03896511842464997),\n",
       " ('without', 0.038529606125760126)]"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left his assigned area without permission at which time an inmate was able to open cells on dorm.',\n",
       " 'deputy frazier allowed offender to come out of his cell for recreation time without notifying his supervisor.',\n",
       " 'deputy frazier allowed offender to come out of his cell for recreation time without notifying his supervisor.']"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_representative_docs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.DataFrame({\"topic\": topic, \"documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the former chief of police received a complain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>alleges officer burr made inappropriate facebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>refused an assignment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>left work without informing her rank.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>failed to inform his supervisor that he would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>2</td>\n",
       "      <td>officer failed to activate his body-worn camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>13</td>\n",
       "      <td>officers accused of not making an arrest in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>-1</td>\n",
       "      <td>complainant stated that the officer discrimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>-1</td>\n",
       "      <td>the complainant stated the officer was instruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>-1</td>\n",
       "      <td>the complainant stated the officer was instruc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1543 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                          documents\n",
       "0         0  the former chief of police received a complain...\n",
       "1        -1  alleges officer burr made inappropriate facebo...\n",
       "2        -1                             refused an assignment.\n",
       "3        27              left work without informing her rank.\n",
       "4        21  failed to inform his supervisor that he would ...\n",
       "...     ...                                                ...\n",
       "1538      2  officer failed to activate his body-worn camer...\n",
       "1539     13  officers accused of not making an arrest in a ...\n",
       "1540     -1  complainant stated that the officer discrimina...\n",
       "1541     -1  the complainant stated the officer was instruc...\n",
       "1542     -1  the complainant stated the officer was instruc...\n",
       "\n",
       "[1543 rows x 2 columns]"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ gensim ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = og_df.allegation_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(descs, allowed_pos_tags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    final_text = []\n",
    "    for desc in descs:\n",
    "        doc = nlp(desc)\n",
    "        new_text = \" \".join([token.lemma_ for token in doc if token.pos_ in allowed_pos_tags])\n",
    "        final_text.append(new_text)\n",
    "    return (final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_texts = lemmatization(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = gen_words(lemmatized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = gensim.models.Phrases(data_words, min_count=5, threshold=50)\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[data_words], threshold=50)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return list(bigram[doc] for doc in texts)\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return list(trigram[bigram[doc]] for doc in texts)\n",
    "\n",
    "data_bigrams = make_bigrams(data_words)\n",
    "data_bigrams_trigrams = make_trigrams(data_words)\n",
    "\n",
    "# print(data_bigrams_trigrams[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "texts = data_bigrams_trigrams\n",
    "\n",
    "train_corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# print(train_corpus[0][0:20])\n",
    "\n",
    "tdidf = TfidfModel(train_corpus, id2word=id2word)\n",
    "\n",
    "low_value = 0.03\n",
    "words = []\n",
    "words_missing_in_tdif = []\n",
    "\n",
    "for i in range(0, len(train_corpus)):\n",
    "    bow = train_corpus[i]\n",
    "    low_value_words = []\n",
    "    tdif_ids = [id for id, value in tdidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_value_words = [id for id, value in tdidf[bow] if value < low_value]\n",
    "    drops = low_value_words+words_missing_in_tdif\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tdif = [id for id in bow_ids if id not in tdif_ids]\n",
    "\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tdif]\n",
    "    train_corpus[i] = new_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# corpus = []\n",
    "# for text in data_words:\n",
    "#     new = id2word.doc2bow(text)\n",
    "#     corpus.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = gensim.models.ldamodel.LdaModel(corpus=train_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                        #    per_word_topics=True,\n",
    "                                           alpha=\"auto\")\n",
    "gensim_model.save('models/gensim_train.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim_model.print_topics(5, num_words=20)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_vecs():\n",
    "    gensim_train_vecs = []\n",
    "    for i in range(len(train_docs)):\n",
    "        top_topics = gensim_model.get_document_topics(train_corpus[i], minimum_probability=0.0)\n",
    "        topic_vec = [top_topics[i][1] for i in range(20)]\n",
    "        topic_vec.extend([len(train_docs.iloc[i])]) \n",
    "        gensim_train_vecs.append(topic_vec)\n",
    "    return gensim_train_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_vecs = gensim_vecs()\n",
    "gensim_vecs = np.array(gensim_vecs)\n",
    "gensim_vecs = pd.DataFrame(gensim_vecs).to_csv(\"vecs/gensim_train_vecs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_doc = train_corpus[-1]\n",
    "\n",
    "# vector = lda_model[test_doc]\n",
    "\n",
    "# def Sort(sub_li):\n",
    "#     sub_li.sort(key = lambda x: x[1])\n",
    "#     sub_li.reverse()\n",
    "#     return (sub_li)\n",
    "\n",
    "# new_vector = Sort(vector)\n",
    "# print(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1548021740535992649680788504\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1548021740535992649680788504_data = {\"mdsDat\": {\"x\": [-0.4835960732967876, -0.4398821392936532, 0.028766392757716936, -0.1675985390223408, 0.08907204440376121, -0.125424990535809, -0.2776160646027183, -0.22377640784767283, 0.2031084462417353, 0.3647327037270825, 0.18549273301976651, 0.29706886523248527, -0.057630656815553793, -0.03748378137885758, -0.024949588441776638, 0.11248672493492928, 0.06359104238934574, 0.24208040207509296, 0.16826838252179296, 0.08329050393146137], \"y\": [-0.2855219190070608, 0.09196589278090161, -0.4104854437629844, -0.3372729236668895, 0.3511066685992988, 0.35089672170975295, 0.20813164210582064, -0.055482537940627186, -0.2939698221538226, -0.10377216399061029, -0.1370992990054883, 0.21751026517912886, -0.07091869309044771, 0.05750769422544344, 0.1669864447122465, 0.18863638171972597, -0.08040096504675774, 0.02664332686039519, 0.07884007356330629, 0.03669865620866865], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [50.90466336310543, 7.721137700047831, 5.096962936661238, 4.926975692575182, 3.348895529086879, 3.347901541561037, 3.3386447662415204, 2.9269206453212826, 2.918520853033493, 2.8636349777745433, 1.8031608566063915, 1.7980123066968994, 1.501952412373637, 1.3261461943036417, 1.2795865071443817, 1.165287180614183, 1.1223452159156824, 1.0363235456457192, 0.9418570742817265, 0.6310707010093083]}, \"tinfo\": {\"Term\": [\"fail\", \"officer\", \"complainant\", \"arrest\", \"accuse\", \"call\", \"take\", \"allege\", \"incident\", \"duty\", \"supervisor\", \"state\", \"unprofessional\", \"make\", \"subject\", \"refuse\", \"child\", \"document\", \"work\", \"home\", \"use\", \"conduct\", \"observe\", \"leave\", \"time\", \"complete\", \"properly\", \"go\", \"back\", \"come\", \"officer\", \"complainant\", \"accuse\", \"state\", \"police\", \"give\", \"complaint\", \"report\", \"check\", \"order\", \"prior\", \"end\", \"receive\", \"attend\", \"personal\", \"refuse\", \"training\", \"verbal\", \"own\", \"former\", \"history\", \"reprimand\", \"assignmnet\", \"chief\", \"misuse\", \"vehicle\", \"allegation\", \"stop\", \"accident\", \"rude\", \"traffic\", \"arrest\", \"unprofessional\", \"subject\", \"speak\", \"employee\", \"manner\", \"put\", \"money\", \"system\", \"timely_manner\", \"disrespectful\", \"lieutenant\", \"display\", \"serve\", \"attitude\", \"oder\", \"tiger\", \"paper\", \"blachard\", \"harassign\", \"cbm\", \"major\", \"evacuatin\", \"fill\", \"follow\", \"warrant\", \"son\", \"vehicle\", \"rude\", \"tell\", \"allegation\", \"rank\", \"fail\", \"rank\", \"notify\", \"allegation\", \"action\", \"domestic_violence\", \"neglect\", \"professionalism\", \"activate_body_wear_camera\", \"traffic\", \"activate_bwc\", \"stop\", \"service\", \"use_force\", \"warrant\", \"appear_court\", \"investigation\", \"appropriate\", \"interview\", \"vehicle\", \"crash\", \"handle\", \"second\", \"question\", \"supervise\", \"domestic\", \"subordinate\", \"rule\", \"occur\", \"witness\", \"accident\", \"request\", \"rude\", \"steal\", \"also\", \"involve\", \"evidence\", \"report\", \"allege\", \"supervisor\", \"properly\", \"allow\", \"inappropriate\", \"subpoena\", \"office\", \"deliver\", \"occasion\", \"book\", \"facility\", \"stay\", \"assgned\", \"burr\", \"faceboook\", \"watch\", \"inform\", \"evidence\", \"behavior\", \"property\", \"improperly\", \"aggressive\", \"daughter\", \"front\", \"nopd\", \"demean\", \"welfare\", \"son\", \"falsely\", \"handle\", \"tell\", \"traffic\", \"vehicle\", \"allegation\", \"call\", \"observe\", \"sit\", \"roll\", \"multiple\", \"offender\", \"deputy\", \"frazi\", \"cctv\", \"service\", \"wait\", \"inmate\", \"reply\", \"approach\", \"get\", \"activate_body_wear_camera\", \"bank\", \"line\", \"teller\", \"whitney\", \"respond\", \"son\", \"bwc\", \"girlfriend\", \"operator\", \"in\", \"matter\", \"detective\", \"phone\", \"disconnect\", \"tell\", \"say\", \"feel\", \"vehicle\", \"several\", \"ask\", \"involve\", \"also\", \"allegation\", \"make\", \"unit\", \"policy\", \"show\", \"proper\", \"only\", \"form\", \"approve\", \"correctly\", \"recruit\", \"relate\", \"follow\", \"procedure\", \"prepare\", \"sure\", \"mandatory\", \"require\", \"patrol\", \"sercurity\", \"effort\", \"baker\", \"housing\", \"fill\", \"driver\", \"pedestrian\", \"feel\", \"illegal\", \"use_force\", \"correct\", \"physically\", \"issue\", \"stop\", \"nopd\", \"allegation\", \"vehicle\", \"incident\", \"emergency\", \"sleep\", \"family\", \"supervisory\", \"present\", \"duty\", \"effect\", \"narcotic\", \"ihop\", \"allegation\", \"neglect\", \"involve\", \"rude\", \"handle\", \"domestic\", \"use_force\", \"professionalism\", \"domestic_violence\", \"remove\", \"rule\", \"sustain\", \"mother\", \"pursuit\", \"weapon\", \"center\", \"signal\", \"action\", \"respond\", \"month\", \"also\", \"accident\", \"traffic\", \"vehicle\", \"nopd\", \"warrant\", \"home\", \"back\", \"attempt\", \"contact\", \"tour\", \"late\", \"approval\", \"schedule\", \"minute_late\", \"incorrect\", \"engage_verbal_altercation\", \"medication\", \"lunch_break\", \"cmt\", \"retune\", \"reynold\", \"abandon\", \"info\", \"unsuccessful\", \"extend\", \"pregancy\", \"duty\", \"lunch\", \"vehicle\", \"consciousness\", \"knee\", \"throw\", \"lose\", \"custody\", \"ground\", \"place\", \"report\", \"search\", \"number\", \"allegation\", \"stop\", \"neglect\", \"take\", \"hour\", \"return\", \"break\", \"extended\", \"min\", \"azccuse\", \"leave\", \"action\", \"statement\", \"accident\", \"crime\", \"threaten\", \"appropriate\", \"allotted\", \"go_district_station\", \"witness\", \"day\", \"scene\", \"like\", \"jail\", \"clothe\", \"reimburse\", \"primary\", \"boyfriend\", \"prevent\", \"necessary\", \"sustain\", \"discrimination\", \"window\", \"vehicle\", \"traffic\", \"neglect\", \"tell\", \"evidence\", \"allegation\", \"advise\", \"professionalism\", \"involve\", \"also\", \"say\", \"child\", \"work\", \"time\", \"unauthorized\", \"need\", \"neighborhood\", \"lie\", \"annual\", \"pay_detail\", \"inform\", \"deny\", \"early\", \"chapman\", \"treport\", \"flood\", \"uof\", \"demean\", \"welfare\", \"do\", \"falsely\", \"front\", \"son\", \"allotted\", \"pursuit\", \"possible\", \"parent\", \"upset\", \"testify\", \"place\", \"victim\", \"number\", \"say\", \"vehicle\", \"document\", \"turn\", \"post\", \"year\", \"submit\", \"log\", \"previous\", \"daily\", \"sheet\", \"security_patrol\", \"create\", \"completion\", \"affair\", \"course\", \"signin\", \"security\", \"internal\", \"documation\", \"falsfe\", \"lunch_break\", \"include\", \"mother\", \"dismissive\", \"accurately\", \"traffic\", \"medical\", \"social_medium\", \"domestic_violence\", \"signal\", \"involve\", \"pursuit\", \"accident\", \"allegation\", \"professionalism\", \"rude\", \"vehicle\", \"stop\", \"also\", \"use\", \"conduct\", \"language\", \"minute\", \"area\", \"vulgar\", \"tone\", \"co_worker\", \"remain\", \"class\", \"acceptance\", \"elevated\", \"media\", \"platform\", \"refer\", \"trump\", \"social\", \"stop\", \"vehicle\", \"unauthorized_force\", \"upset\", \"search\", \"location\", \"confront\", \"profiling\", \"racial\", \"improper\", \"body\", \"traffic\", \"allegation\", \"professionalism\", \"rude\", \"become\", \"detail\", \"station\", \"camera\", \"unable\", \"opso\", \"sick\", \"wear\", \"dorm\", \"verbally\", \"agent\", \"hat\", \"cooperate\", \"confrontational\", \"unapproved\", \"attire\", \"nofty\", \"laptop\", \"movie\", \"wrrite\", \"dugar\", \"harrison\", \"watch\", \"deputy\", \"stop\", \"allotted\", \"confront\", \"profiling\", \"racial\", \"location\", \"traffic\", \"vehicle\", \"upset\", \"come\", \"provide\", \"perform\", \"answer\", \"communication\", \"admit\", \"statistic\", \"smoke\", \"datum\", \"weekly\", \"number\", \"summon\", \"badge\", \"draw\", \"reason\", \"gun\", \"one\", \"bi\", \"consideration\", \"disorder\", \"introduce\", \"polar\", \"just\", \"documentation\", \"suffer\", \"attack\", \"evaluation\", \"house\", \"search\", \"handcuff\", \"tell\", \"vehicle\", \"stop\", \"son\", \"warrant\", \"ask\", \"neglect\", \"store\", \"party\", \"enter\", \"assign\", \"assist\", \"protection\", \"disciplinary\", \"shift\", \"utilize\", \"numerous\", \"granddaughter\", \"as\", \"anti\", \"breach\", \"virus\", \"shakedown\", \"ballot\", \"pan\", \"other\", \"aggressive\", \"improperly\", \"behavior\", \"property\", \"believe\", \"evidence\", \"smell\", \"pib\", \"alcohol\", \"know\", \"act\", \"accident\", \"vehicle\", \"violation\", \"say\", \"tell\", \"action\", \"instruct\", \"instruction\", \"so\", \"assignment\", \"target\", \"clean\", \"inspection\", \"solution\", \"backup\", \"ready\", \"tdc\", \"assisite\", \"lunch\", \"refuse\", \"comply\", \"parent\", \"batter\", \"threaten\", \"count\", \"inclement\", \"weather\", \"relocate\", \"fic\", \"finish\", \"release\", \"discuss\", \"heated\", \"fourth\", \"qualified\", \"unconscious\", \"however\", \"argumentative\", \"remark\", \"medical\", \"paragraph\", \"rule\", \"professionalism\", \"allegation\", \"service\", \"rude\", \"place\", \"crime\", \"daughter\", \"neglect\", \"inmate\", \"action\", \"go\", \"physical_altercation\", \"sign\", \"partner\", \"extended_lunch_break\", \"notify\", \"lunch\", \"therapy\", \"get\", \"discharge\", \"neighbor\", \"reply\", \"adherence\", \"female\", \"law\", \"say\", \"non\", \"approach\", \"caretaker\", \"clock\", \"situation\", \"continue\", \"commander\", \"however\", \"arrive\", \"church\", \"involvement\", \"father\", \"speed\", \"online\", \"ask\", \"tell\", \"write\", \"injury\", \"also\", \"vehicle\", \"nopd\", \"advise\", \"feel\", \"allegation\", \"complete\", \"send\", \"item\", \"miss\", \"frame\", \"packet\", \"fake\", \"rporte\", \"uof\", \"letter\", \"certify\", \"tow\", \"misconduct\", \"file\", \"nopd\", \"question\", \"domestic_violence\", \"number\", \"investigation\", \"empathy\", \"lack\", \"case\", \"accurately\", \"warrant\", \"girlfriend\", \"ip\", \"application\", \"brother\", \"retaliation\", \"package\", \"evaluation\", \"use_force\", \"professional\", \"son\", \"want\", \"allegation\", \"neglect\", \"write\", \"professionalism\", \"vehicle\", \"accident\", \"battery\", \"authorization\", \"leave\", \"control\", \"pod\", \"repot\", \"district\", \"motorist\", \"dispatch\", \"activity\", \"room\", \"unattended\", \"university\", \"center\", \"medical\", \"also\", \"crime\", \"lab\", \"assign_area\", \"parking\", \"scene\", \"clear\", \"fecal\", \"toilet\", \"door\", \"unlocked\", \"stop\", \"carry\", \"business\", \"thus\", \"permission\", \"matter\", \"place\", \"vehicle\", \"pursuit\", \"accident\", \"action\", \"allegation\", \"find\", \"cell_phone\", \"possession\", \"warrant\", \"search\", \"property\", \"son\", \"sister\", \"seat\", \"husband\", \"revolver\", \"epr\", \"girlfriend\", \"distribute\", \"intent\", \"thus\", \"handgun\", \"passenger\", \"residence\", \"damage\", \"ambulance\", \"intersection\", \"pcd\", \"bed\", \"yard\", \"beginning\", \"excuse\", \"responsible\", \"insist\", \"narcotie\", \"window\", \"later\", \"say\", \"bwc\", \"steal\", \"have\", \"vehicle\", \"ask\", \"drive\", \"front\", \"neglect\", \"also\"], \"Freq\": [735.0, 2887.0, 2400.0, 537.0, 1639.0, 280.0, 266.0, 285.0, 227.0, 240.0, 228.0, 1027.0, 213.0, 138.0, 186.0, 120.0, 106.0, 89.0, 92.0, 91.0, 79.0, 78.0, 86.0, 62.0, 79.0, 56.0, 90.0, 57.0, 73.0, 57.0, 2886.5747459307318, 2398.973982178983, 1638.2970708157686, 1025.9635672712268, 362.8569060970513, 162.96355504962094, 123.8109278617155, 347.7471670521109, 75.93584388257462, 50.66602026515437, 38.40411713518846, 23.541812283521512, 17.47399760038343, 11.96877099478522, 10.65419301787077, 104.9601871125269, 8.401552612024684, 5.810524968530593, 4.477467682309337, 2.7850348852079594, 2.488257734736715, 2.116925421107793, 1.2890477041463682, 0.9333159677239926, 0.6110558340014477, 0.0904817174815408, 0.090235894716466, 0.09012938990097509, 0.0901041682508989, 0.09009870513981304, 0.09010518504444484, 536.5706898629318, 211.9991881372678, 184.6936369264317, 103.87911052562215, 77.80722102462084, 27.261966027533468, 26.76570309078223, 18.812836511505942, 15.29083757892401, 13.45408734243296, 12.532225784265329, 10.399891691430051, 8.171999700706701, 7.079684020282107, 6.988745487995242, 2.6405978108423835, 2.6405978108423835, 2.313064513492205, 0.8701849567617326, 0.8701849567617326, 0.7531365193950696, 0.7531263143645875, 0.7530019300996121, 1.0683484971548889, 6.061289565576401, 0.08556974521559507, 0.08558196824903119, 0.08569023463030952, 0.08555725032683872, 0.08556220123045892, 0.08560590720117149, 0.18643045297991365, 734.4613044576989, 17.621676015418156, 34.2714321087939, 0.08778866575471705, 0.08766922122358535, 0.08761711566071258, 0.08766037245797362, 0.08760964735775478, 0.0875705871669617, 0.08762321730564297, 0.08755841838866726, 0.08762189896380845, 0.08757663359338594, 0.08757714436456789, 0.08758106487850506, 0.08755199923732647, 0.0875744110485131, 0.08755698270750717, 0.08755416656369315, 0.0877200084446236, 0.08755193021419377, 0.08756940687139259, 0.08754648428902399, 0.08755036338908155, 0.0875365380556024, 0.08754722283654386, 0.0875334872331372, 0.0875428881838105, 0.08753602728442045, 0.08754586308082973, 0.08757472165261024, 0.08754247404501432, 0.08757238176841181, 0.08754531089576816, 0.0875551535944907, 0.08755039099833463, 0.08754683630700075, 0.14056248989131792, 283.7400806329419, 226.7084442633353, 89.5504408211135, 50.726647411618224, 34.34931376808829, 21.721109124820348, 20.03209052219457, 12.651639250936864, 5.186887871403348, 4.098015138056709, 3.150416621834621, 3.0861181305507266, 1.92628760004197, 0.5665350565198656, 0.5665350565198656, 0.8680724406310195, 5.461723552669283, 0.08307480747025724, 0.083029957504209, 0.08304446935725197, 0.08302456643420499, 0.08302436627071474, 0.0830320592208566, 0.08302619443059234, 0.08302776237793262, 0.08300479695348482, 0.08300479695348482, 0.08303604247431254, 0.08300563096802753, 0.0830133572787511, 0.08303348038163737, 0.08303629601473352, 0.0831022765732356, 0.08304805895584376, 279.1286184567126, 85.61873978206683, 27.232354320041363, 16.17201668398136, 7.882443842060189, 5.194341407741367, 9.627118797633521, 2.2074550986086914, 0.7914340027375111, 0.10267445406103123, 0.1025886594496063, 0.10259100862016968, 0.10257823783965521, 0.10257564377486321, 0.10259362082527491, 0.10255737647943983, 0.1025459208716346, 0.1025459208716346, 0.1025459208716346, 0.1025459208716346, 0.10255760323335521, 0.10259604255709122, 0.10255415657384137, 0.10253851055367982, 0.10253898220182382, 0.10253444712351613, 0.10253851962383644, 0.10254753535951214, 0.10253816588772843, 0.10253378500208321, 0.10258651889264506, 0.10257084566201367, 0.10257401114667244, 0.1026550348557177, 0.10254108647815859, 0.10254541294286414, 0.10254824283172813, 0.10254889588300443, 0.1025565964459709, 137.6039275468673, 57.46942633370302, 46.13605787898615, 39.426150399948845, 26.049531972262347, 25.278823604297447, 24.689545770758592, 23.92257000641904, 8.339347968558494, 8.059474656055752, 6.8872316852212885, 36.88519673089056, 6.735559843877915, 5.75593709389735, 5.0914303520301125, 4.544194796918729, 3.6553314182985024, 3.360550904003488, 1.8247160992181675, 1.4055717548978668, 0.7110503998299843, 0.7110503998299843, 0.7004703371752105, 0.0807736356660343, 0.08076008887407547, 0.08078520575073274, 0.080727527609066, 0.08074072983737393, 0.08069057769123987, 0.08069065929842034, 0.08069688864652994, 0.08074403946191541, 0.0807141984362551, 0.08073475437827027, 0.08072876985170212, 226.47830080796442, 24.812216445043646, 15.853519992380205, 12.630304022994578, 9.791292260997256, 5.742585344978786, 188.93842689406932, 2.2779542538300537, 1.9879972493092741, 0.9468545512421598, 0.07175731911561165, 0.07169501250371725, 0.0715363411050935, 0.07153391774365563, 0.07148817227531896, 0.07148058570723546, 0.0714892392777431, 0.07149320436725994, 0.07148300906867333, 0.07146767769062139, 0.07146880346860279, 0.07146290782808974, 0.07146178205010835, 0.07147557170008134, 0.07145781696059152, 0.07145424973638538, 0.07145383830748456, 0.07149432562404462, 0.07146139322719107, 0.07144963811573868, 0.07148496222565312, 0.07147902589436966, 0.07148504812839065, 0.07151330108664682, 0.07146562054611721, 0.071464051690858, 90.40538490363811, 72.22237767789697, 54.230526190457056, 48.53571518981332, 14.191344052293054, 12.028820943939996, 9.422672598858645, 8.951232633494174, 5.705906146939971, 2.827003348162029, 2.6191749570115745, 2.1198048418310584, 1.9239750530912916, 1.245186772582712, 1.245186772582712, 1.245186772582712, 0.7646163577088813, 0.6695953006237583, 0.6695953006237583, 0.6694300327145718, 0.6692035027945358, 49.84879929588661, 0.6697235957044505, 0.08702302728485894, 0.08679166172473256, 0.08679166172473256, 0.08679166965201139, 0.08679172514296325, 0.08679222456152996, 0.08679168550656907, 0.08680529664433159, 2.885776827639237, 0.08679990609472267, 0.08679511801830533, 0.08681409592384026, 0.08680135678674977, 0.08679737729277379, 265.4031678805265, 54.94285861176304, 49.70474565472171, 20.520571644414993, 1.2025921056923057, 1.2025921056923057, 0.5973324691512645, 6.5586756655883995, 0.07759973958003573, 0.07747216838942204, 0.07748438088644777, 0.07743204500113558, 0.07743858995099792, 0.07742396657268233, 0.07742142921893135, 0.077418820724421, 0.07742655135360621, 0.07741927918709252, 0.07742361086888545, 0.07740278243544677, 0.07740167580141208, 0.0773961821538827, 0.07739554979157716, 0.07739555769610598, 0.07739862465328785, 0.07739123391884185, 0.07739071221993979, 0.07739643509880492, 0.07739426135337962, 0.07739559721875008, 0.07752789531759767, 0.07743123873919602, 0.07742949974285579, 0.07742065457510706, 0.07740455304990228, 0.07743964125333087, 0.07740064030813676, 0.077403778406078, 0.077404521431787, 0.07740477437670922, 0.07740273500827385, 104.87119478666148, 91.32532269557275, 78.23541767317649, 32.01890985611357, 15.30548051515359, 11.121963599059937, 9.603023102927757, 7.729306263317985, 7.118742873795095, 17.96396441547508, 3.4470172143139957, 2.662947313764763, 0.7113797851489129, 0.7110729006558855, 0.6225934353811865, 1.0249386746412226, 0.08075391496485865, 0.08075391496485865, 0.08075475259944334, 0.08075400027949228, 0.08075613314533292, 0.08076461807344079, 0.08072908065059778, 0.0807419476485237, 0.08071935478236444, 0.08071302598772458, 0.08071827671563045, 0.08069292275769205, 0.08071197894449372, 0.08070101213613493, 0.08070504519154269, 0.08071633774668441, 0.080761376117363, 88.58271860374164, 23.503797329269332, 20.354639614889297, 16.965112699594084, 15.478760857448112, 14.870678450865793, 5.868135436073581, 3.748490745060301, 3.5907259920080143, 1.5834105915584795, 1.529398127719023, 1.3448692172526397, 1.3369092011491304, 0.5588884990700159, 0.5588884990700159, 0.5588829902731641, 0.5585751227611603, 0.4949873932561673, 0.4949873932561673, 0.6378782776000295, 0.07242622289370611, 0.07242554894515509, 0.07241748598096857, 0.07241857504275755, 0.07246629841406625, 0.07241975201087926, 0.07241584017907222, 0.07243189773585314, 0.07241439949195229, 0.07244612879438707, 0.07243247401070112, 0.07244388718290215, 0.07246302146132903, 0.07243056448980655, 0.07243343121299098, 0.07246168333159729, 0.0724358877066226, 0.07243160959842915, 77.65934146605423, 77.05646973572648, 17.948152337754447, 16.068424282800983, 13.188294075958922, 9.15153606883509, 8.751825873372946, 3.1918160582893207, 3.068803133025409, 0.7347828797427299, 0.4474387588642602, 0.4474387588642602, 0.05803674795788996, 0.05803674795788996, 0.05803674795788996, 0.05803674795788996, 0.05803674795788996, 0.05807885660665263, 0.05813812135228021, 0.058022942242700624, 0.05801857895493708, 0.05801791180044645, 0.05799948470123078, 0.05799609536162874, 0.05799609536162874, 0.05799609536162874, 0.05798884431756633, 0.05798838169218962, 0.058027427273984356, 0.058062864377840716, 0.058003692157288476, 0.05800926801051309, 35.67779048635924, 29.472359877714705, 22.235567126464613, 17.923388668735917, 9.250898118114877, 6.270321092933434, 4.871331425638833, 4.499914318328021, 4.39365031857572, 3.7844592914240187, 2.732147702926187, 1.2881182109299987, 1.2052385341976244, 1.1949284794988235, 1.1197487681155327, 1.1196611620044978, 0.9838263247746367, 0.8334141170481375, 0.8334141170481375, 0.6044345880816301, 0.5290601385971386, 0.5290301338295404, 0.8286615831538927, 1.7288575262298282, 0.06867991233078284, 0.06861788512140972, 0.06860305358905307, 0.06860305358905307, 0.06860305358905307, 0.06860305358905307, 0.06863806999896149, 0.0686737454072906, 0.06860305358905307, 56.60297683511433, 33.32084561169037, 17.57195038604024, 7.024855149643213, 4.772283812304012, 4.749930677033046, 2.4198357370955543, 0.6540935585562588, 0.5661947193271387, 0.5661947193271387, 0.06426143511184762, 0.06423697537942823, 0.06423433186062344, 0.06422563267238265, 0.06422832647551253, 0.06422939681328949, 0.06422474910495604, 0.06422243602600185, 0.06422243602600185, 0.06422243602600185, 0.06422243602600185, 0.06422243602600185, 0.06422631510250888, 0.06422243602600185, 0.06422243602600185, 0.06422321902477826, 0.06422243602600185, 0.06422359974895396, 0.06423604152767654, 0.06422694724831003, 0.06425096878875362, 0.06429228813702861, 0.06423615646327675, 0.06422741417418588, 0.06422565422280768, 0.06422476347190607, 0.06422543871855729, 28.13386503183763, 24.148251097896875, 16.050199393378637, 15.759431163505015, 11.227289784239641, 9.262568102635775, 4.533608812358507, 4.3923719259548575, 2.105166961491584, 1.5844541173903472, 1.5480140451810103, 1.1456874083313116, 0.8906481577866481, 0.8906481577866481, 0.8906481577866481, 0.547026164083675, 0.47895975914811184, 0.4787981219252248, 0.06211520241218236, 0.062072783038079934, 0.062072783038079934, 0.062073469233837476, 0.06208432360309309, 0.06207285928205299, 0.06208064309857539, 0.06206045230825506, 0.062061235541796496, 0.06206045230825506, 0.062062732696176584, 0.06205782535681963, 0.06208798331379997, 0.06213806174155978, 0.06206627457528873, 0.06206953227231947, 0.06207014222410395, 0.06206931047167057, 35.683627464747836, 28.51872897239628, 13.414516268275197, 9.65782710082024, 3.2769601810189584, 2.126960420322594, 1.523382129934644, 1.3499871255493994, 1.0395288462003567, 0.5736114130450778, 0.5736114130450778, 0.43445149993664456, 0.7930140409945436, 14.169457087562792, 0.05636498191320043, 0.05634113467418782, 0.05632384574151032, 0.056324742064416566, 0.05629895700052918, 0.0562994051619823, 0.0562994051619823, 0.056300156305826264, 0.05629845202987777, 0.05629784606509609, 0.0562994051619823, 0.05629708229698584, 0.05629708229698584, 0.056297246412447544, 0.056297246412447544, 0.056297246412447544, 0.05630109050153136, 0.05629784606509609, 0.056298553024008054, 0.05630227087042903, 0.056303470175726116, 0.056303470175726116, 0.05631063444684293, 0.05633521389330009, 0.05630697972175338, 0.05631230716212571, 0.056304132949706084, 0.05630257385281987, 0.05630237186455931, 0.05631063444684293, 0.05630232767962731, 0.05630540800060088, 56.2322054965552, 9.82064158148413, 9.1856294661963, 2.8721274804433734, 2.0705118701432292, 14.610809171107125, 0.6300337625706934, 0.06137971632506965, 0.06138903015722248, 0.0613641952979899, 0.06135959917716252, 0.06135958093858781, 0.06135500913586005, 0.061363173937806034, 0.06135500913586005, 0.06137966768887042, 0.0613513857390173, 0.06135718560577565, 0.06135072307080277, 0.0613487533047339, 0.061347987284596, 0.06135116687612076, 0.06134787785314773, 0.0613487533047339, 0.06135361084513214, 0.06134311758514795, 0.06134235764453495, 0.06134435172870344, 0.06134473473877239, 0.06134235764453495, 0.06136152638655707, 0.061377497298479716, 0.06135172011288702, 0.0613487533047339, 0.0613637332540972, 0.06140563941926004, 0.06135379323087926, 0.061350796025101614, 0.06135355612940801, 0.06135500913586005, 55.530518100077245, 12.966458791950467, 11.955365145257089, 6.029908641496618, 3.281392131074235, 2.205503604589365, 0.9080603480585273, 0.7622985890842758, 1.0904880098930112, 0.05315117832340804, 0.05314920796303678, 0.05314920796303678, 0.05313627431547163, 0.05313718932612837, 0.05315044856030757, 0.053135567006620414, 0.05314058553132668, 0.05313584207117367, 0.053138109950347415, 0.05311986587283581, 0.05311986587283581, 0.05312288035579696, 0.05312253792849597, 0.05314043957870659, 0.053122150592696496, 0.053118428800884125, 0.053118838590932846, 0.05311772149203291, 0.053120438456191556, 0.05311774955984446, 0.05312161169071461, 0.05313451165690589, 0.05312146573809452, 0.05313985015466391, 0.05312751715826606, 0.053163612363927484, 0.05314324074629991, 0.05312421638362704, 0.053128061673810255, 0.05315044856030757, 0.053129094569275524, 0.05312355398327431, 10.370652973585887, 55.07446010326639, 6.160771291293691, 3.3942005559276094, 1.289070497150639, 0.05350429012218289, 0.05350429012218289, 0.05350429012218289, 0.05350429012218289, 0.053492668094488584, 0.0534905100094514, 0.053489678406942985, 0.053489678406942985, 0.053489678406942985, 0.05350921341310695, 0.05348545407027447, 0.05347716355446971, 0.053474530996835704, 0.053474786089629696, 0.05348897435083157, 0.053472204550554486, 0.05347091888287276, 0.05347091888287276, 0.05347395958897715, 0.0534701995211937, 0.05351341224049607, 0.053469026094341336, 0.05347079643833165, 0.053472219856122126, 0.05346990361355267, 0.05347091888287276, 0.05347589319235562, 0.05350241774107498, 0.05347416876506823, 0.053476433989078885, 0.053472628004592515, 0.05347383204258016, 26.975532511778574, 6.82982651271874, 2.722647601145129, 0.04369657497620751, 0.043689331414631556, 0.04368837426633459, 0.043691191017037084, 0.04366497882724733, 0.043666031690373995, 0.043666226538420165, 0.0436623979452323, 0.04366016915705508, 0.043662883356154335, 0.04365922910069199, 0.04365922910069199, 0.0436623979452323, 0.04366034007639383, 0.04366034007639383, 0.04366692388932224, 0.04366124594888917, 0.04365550989588093, 0.04365550989588093, 0.04365550989588093, 0.0436549834643176, 0.0436549834643176, 0.043655301374287664, 0.043655301374287664, 0.043655301374287664, 0.0436549834643176, 0.04365502790334567, 0.043659106038768096, 0.04366034007639383, 0.043669474005856294, 0.04366016915705508, 0.043660613547335816, 0.043658220676593404, 0.043695993850455785, 0.04366195013656479, 0.0436576224589078, 0.04366034007639383, 0.04366564541266844, 0.04366068875184487], \"Total\": [735.0, 2887.0, 2400.0, 537.0, 1639.0, 280.0, 266.0, 285.0, 227.0, 240.0, 228.0, 1027.0, 213.0, 138.0, 186.0, 120.0, 106.0, 89.0, 92.0, 91.0, 79.0, 78.0, 86.0, 62.0, 79.0, 56.0, 90.0, 57.0, 73.0, 57.0, 2887.9229161174694, 2400.3221523657207, 1639.6452410612812, 1027.311737457964, 364.2050762837889, 164.31172524934271, 125.15909804845305, 351.9474367819339, 77.28401408374017, 52.01419045189194, 39.752287326447224, 24.889982481452385, 18.82216778712099, 13.316941181522791, 12.002363204608342, 120.42152216487277, 9.749722798762255, 7.158695155268156, 5.8256378690469015, 4.133205071945524, 3.836427921474279, 3.465095607845357, 2.6372178959857893, 2.281486154461558, 1.9592260207390129, 1.4409611433640424, 1.440007992076163, 1.4392511213612864, 1.4388512332793737, 1.4388895249958342, 1.4391113495215446, 537.9232995172913, 213.35179780024427, 186.0462465807913, 105.23172017998172, 79.15983069198593, 28.61457568189306, 28.118312745141825, 20.165446165865536, 16.643447233283613, 14.806696996792565, 13.884835438624934, 11.752501345789657, 9.524609355066307, 8.432293688216138, 8.341355142354843, 3.9932074652019818, 3.9932074652019818, 3.6656741678518032, 2.2227946111213317, 2.2227946111213317, 2.1057461737546688, 2.105735968724187, 2.1056115844592114, 3.040805853509936, 44.218473315646804, 1.4386463234164417, 1.4388993757980406, 1.4409611433640424, 1.4388895249958342, 1.439017409095913, 1.440007992076163, 19.073212211936887, 735.8118446670635, 19.073212211936887, 50.17144810402226, 1.440007992076163, 1.439008835481906, 1.438507165397605, 1.43928560318411, 1.438673961212277, 1.4382400503960397, 1.4391113495215446, 1.4381792449733208, 1.4392511213612864, 1.4385503801729298, 1.4385671593265017, 1.4386463234164417, 1.4381689718242674, 1.4385503637184403, 1.4382675229660555, 1.4382227042299567, 1.4409611433640424, 1.438229942666388, 1.438521087847285, 1.4381678909847437, 1.4383433176195348, 1.4381672104031444, 1.4383697120125005, 1.4381540694983834, 1.4383086664520475, 1.438197553577922, 1.4383672290205383, 1.4388512332793737, 1.4383134890277123, 1.4388895249958342, 1.4383849073366, 1.4388550077805962, 1.4388033548617833, 1.4385380060902442, 351.9474367819339, 285.0951840685398, 228.0635476989332, 90.90554425671138, 52.081750847216135, 35.7044172036862, 23.076212560418245, 21.387193957792466, 14.006742686534773, 6.541991307001251, 5.4531186112182635, 4.505520057432523, 4.441221566148629, 3.2813910356398734, 1.9216384921177694, 1.9216384921177694, 2.9832990852683845, 24.700127518983507, 1.4385380060902442, 1.438274718759502, 1.4385449612419872, 1.4382360099867766, 1.4382350561356299, 1.4383721861137353, 1.4385299664297069, 1.4386908695808907, 1.4383062968925444, 1.4383062968925444, 1.4388993757980406, 1.4383803434240574, 1.438521087847285, 1.439017409095913, 1.4391113495215446, 1.4409611433640424, 1.440007992076163, 280.46415352621307, 86.95427485643702, 28.567889389541826, 17.507551753481824, 9.217978911560664, 6.529876477241836, 12.622973019249393, 3.54299016810916, 2.1269690722379804, 1.4385503801729298, 1.4382626241987817, 1.4383681760563725, 1.438220578706013, 1.4382530792827388, 1.43857533920506, 1.4382400503960397, 1.4381113341214502, 1.4381113341214502, 1.4381113341214502, 1.4381113341214502, 1.4383468211310142, 1.4388993757980406, 1.438315365258959, 1.4381593830237371, 1.4381753298465676, 1.438115884363751, 1.4381734585882289, 1.4383013056433747, 1.438182776885793, 1.4381248331166958, 1.439017409095913, 1.438772170082097, 1.4388931360956017, 1.4409611433640424, 1.4382642662986393, 1.4385478055178584, 1.4388033548617833, 1.4388550077805962, 1.440007992076163, 138.961349031873, 58.82684781870872, 47.49347936399185, 40.78357188495455, 27.40695345726804, 26.63624508930314, 26.046967265531656, 25.279991491424735, 9.6967694535642, 9.416896141061455, 8.244653176306514, 44.218473315646804, 8.092981328883614, 7.113358587519944, 6.448851837035812, 5.901616281924428, 5.012752903304202, 4.717972389009187, 3.182137584223867, 2.762993239903566, 2.0684718848356844, 2.0684718848356844, 3.040805853509936, 1.4384793877983242, 1.438324880100393, 1.4388931360956017, 1.4382244191764952, 1.4385671593265017, 1.4381846659216266, 1.4381912523662386, 1.4383076829785766, 1.4392511213612864, 1.4386908695808907, 1.440007992076163, 1.4409611433640424, 227.84491926141908, 26.178834928225484, 17.220138445834895, 13.996922476449274, 11.157910740282382, 7.1092038219289355, 240.06710840129222, 3.6445727072847465, 3.354615706182354, 2.313473004696853, 1.440007992076163, 1.43928560318411, 1.4388033548617833, 1.4388895249958342, 1.438521087847285, 1.4383697120125005, 1.4385671593265017, 1.438673961212277, 1.438507165397605, 1.4382734379960438, 1.4383086664520475, 1.43822185965361, 1.4382117262828567, 1.4385479295166854, 1.4382298173203998, 1.4381608098693122, 1.438166350817553, 1.439008835481906, 1.4383468211310142, 1.4381240514841422, 1.4388550077805962, 1.4388512332793737, 1.4391113495215446, 1.4409611433640424, 1.4386908695808907, 1.4386463234164417, 91.75669278170515, 73.57368555596402, 55.58183406852414, 49.8870230678804, 15.542651930360135, 13.380128822007077, 10.77398057770413, 10.302540511561254, 7.057214025007047, 4.178311226229105, 3.9704828350786507, 3.4711127198981346, 3.8407712569943175, 2.5964946506497886, 2.5964946506497886, 2.5964946506497886, 2.115924235775958, 2.020903178690835, 2.020903178690835, 2.0207379107816488, 2.0205113808616124, 240.06710840129222, 3.326453665036996, 1.4409611433640424, 1.4381407807217403, 1.4381407807217403, 1.4381606296472262, 1.4381943755507387, 1.4382045957480671, 1.438205632063564, 1.4384658657368599, 351.9474367819339, 1.4385126890164892, 1.4384309698515243, 1.440007992076163, 1.4392511213612864, 1.43928560318411, 266.7638416505583, 56.30353238179481, 51.06541942475348, 21.881245414446752, 2.5632658757240665, 2.5632658757240665, 1.9580062391830255, 62.94036215216824, 1.439008835481906, 1.4383880782505243, 1.4388512332793737, 1.4383606207898305, 1.4384983268256317, 1.4382675229660555, 1.438268009298565, 1.43822151220078, 1.4383672290205383, 1.438241134708191, 1.4385087468592432, 1.4381302589381637, 1.438151455520549, 1.438077167540838, 1.4380889481961632, 1.4380930649826351, 1.4381950206475462, 1.438116126153456, 1.4381066290091828, 1.43822185965361, 1.4381857539301044, 1.4382243785483182, 1.4409611433640424, 1.4391113495215446, 1.43928560318411, 1.439017409095913, 1.4385380060902442, 1.440007992076163, 1.4384420936885134, 1.438673961212277, 1.4388033548617833, 1.4388550077805962, 1.438772170082097, 106.22857503070506, 92.68270293099944, 79.59279790860317, 33.37629009641002, 16.662860750580297, 12.479343839356385, 10.960403338354466, 9.086686498744694, 8.476123109221803, 24.700127518983507, 4.8043974497407005, 4.020327549191469, 2.068760020575619, 2.0684531360825917, 1.9799736708078925, 3.419695878608058, 1.4383062968925444, 1.4383062968925444, 1.438390547047127, 1.4383803434240574, 1.4385299664297069, 1.4388993757980406, 1.438268009298565, 1.4385479295166854, 1.4381548240888304, 1.4382348148398487, 1.4383432013119115, 1.4381073087176626, 1.4384658657368599, 1.4383037552572093, 1.4384309698515243, 1.438772170082097, 1.4409611433640424, 89.94837277216301, 24.869451497690715, 21.72029378331068, 18.330766868015466, 16.844415025869495, 16.236332645999696, 7.233789604494963, 5.114144920383996, 4.956380160429396, 2.949064759979862, 2.8950522961404053, 2.7105233856740223, 2.702563369570513, 1.9245426674913988, 1.9245426674913988, 1.9245371586945468, 1.924229291182543, 1.86064156167755, 1.86064156167755, 3.8407712569943175, 1.438140499357684, 1.4382117262828567, 1.4381097662679023, 1.4381485655273585, 1.4391113495215446, 1.4382194730795366, 1.4381675487913748, 1.438507165397605, 1.438166350817553, 1.4388033548617833, 1.4385479295166854, 1.4388512332793737, 1.440007992076163, 1.438673961212277, 1.4388895249958342, 1.4409611433640424, 1.4392511213612864, 1.4388550077805962, 79.03943024573887, 78.43655851541112, 19.3282411174391, 17.44851306248563, 14.568382855643575, 10.531624848519744, 10.1319146530576, 4.571904837973972, 4.44889191271006, 2.1148716594273815, 1.827527538548912, 1.827527538548912, 1.4381417177047573, 1.4381417177047573, 1.4381417177047573, 1.4381417177047573, 1.4381528431071509, 1.4392511213612864, 1.4409611433640424, 1.4382217586002375, 1.4383432013119115, 1.4385126890164892, 1.4382607562398309, 1.438205184264032, 1.438205184264032, 1.438205184264032, 1.4381355867371128, 1.4381263072908421, 1.4391113495215446, 1.440007992076163, 1.438673961212277, 1.4388895249958342, 37.04729623243028, 30.84186563154161, 23.60507287253564, 19.292894414806945, 10.62040386418591, 7.639826843525661, 6.240837171709863, 5.869420064399051, 5.76315606464675, 5.153965037495049, 4.101653448997218, 2.6576239570010296, 2.5747442802686553, 2.5644342255698547, 2.489254514186564, 2.489166908075529, 2.3533320708456675, 2.2029198631191687, 2.2029198631191687, 1.9739403341526611, 1.8985658846681697, 1.8985358799005714, 2.9832990852683845, 12.622973019249393, 1.4392511213612864, 1.438268009298565, 1.438205184264032, 1.438205184264032, 1.438205184264032, 1.4382607562398309, 1.4391113495215446, 1.4409611433640424, 1.4383432013119115, 57.976824652755894, 34.694693429331934, 18.945798203681793, 8.398702967284773, 6.146131629945569, 6.123778494674602, 3.793683554737112, 2.0279413761978167, 1.9400425369686967, 1.9400425369686967, 1.4384309698515243, 1.438211452512702, 1.4382326731304709, 1.4381062293514975, 1.438173157728129, 1.4382159961679564, 1.4381723047819988, 1.4381280697218728, 1.4381280697218728, 1.4381280697218728, 1.4381280697218728, 1.4381280697218728, 1.4382192049429499, 1.4381343188528732, 1.4381364159359764, 1.4381695299959076, 1.4381705167140455, 1.4382183093429097, 1.4385126890164892, 1.4383951835104525, 1.439017409095913, 1.4409611433640424, 1.4392511213612864, 1.4388993757980406, 1.4386463234164417, 1.4385478055178584, 1.43928560318411, 29.509871759791896, 25.524257819179024, 17.426206114660786, 17.135437884787162, 12.603296505521795, 10.63857482391793, 5.90961556906066, 5.768378647237009, 3.4811736827737367, 2.9604608386724993, 2.9240207664631623, 2.5216941296134636, 2.2666548790688004, 2.2666548790688004, 2.2666548790688004, 1.9230328853658276, 1.8549664804302644, 1.8548048432073774, 1.4385628290815293, 1.4382350561356299, 1.4382360099867766, 1.438274718759502, 1.4385449612419872, 1.438339190115729, 1.4385380060902442, 1.4380831672248233, 1.438132012905674, 1.4381413356383959, 1.4382312315429118, 1.4381381695191642, 1.4388512332793737, 1.4409611433640424, 1.438371881508889, 1.438772170082097, 1.439017409095913, 1.439008835481906, 37.06537936297884, 29.900480870627273, 14.796268166506193, 11.039578999051237, 4.658712110950562, 3.508712351267792, 2.90513402816564, 2.7317390237803956, 2.421280744431353, 1.955363311276074, 1.955363311276074, 1.8162033981676409, 3.326453665036996, 120.42152216487277, 1.4381861139769816, 1.4382348148398487, 1.4381189746322265, 1.4384983268256317, 1.4380525349079878, 1.4380666785176421, 1.4380666785176421, 1.438095068938742, 1.4380670453705928, 1.4380594408231964, 1.4381010671386993, 1.438056300174219, 1.438056300174219, 1.4380608536950585, 1.4380608536950585, 1.4380608536950585, 1.4381596171078994, 1.4380784541230072, 1.4380996463088147, 1.4382194730795366, 1.4382688544274949, 1.4383086664520475, 1.438673961212277, 1.440007992076163, 1.4385503801729298, 1.4388895249958342, 1.4384658657368599, 1.4383606207898305, 1.4383721861137353, 1.43928560318411, 1.4383681760563725, 1.439008835481906, 57.60891622639537, 11.197352311324291, 10.56234019603646, 4.248838210283534, 3.4472225999833896, 50.17144810402226, 3.326453665036996, 1.4381190475336856, 1.43857533920506, 1.4381523282355, 1.4381870169177093, 1.438220578706013, 1.43811577445927, 1.438332072975657, 1.4381738461236215, 1.438772170082097, 1.438112432388075, 1.4382530792827388, 1.4381151360965694, 1.4380823151069204, 1.4381137130686856, 1.4381941956172182, 1.4381371227603965, 1.4381596171078994, 1.4382895793215842, 1.4380818288757888, 1.4380689776814666, 1.4381314027595469, 1.4381437513666662, 1.438091654942933, 1.4385478055178584, 1.439017409095913, 1.4383446391800605, 1.4382915870516961, 1.4388550077805962, 1.4409611433640424, 1.4386908695808907, 1.4384420936885134, 1.4388931360956017, 1.440007992076163, 56.91545117890983, 14.351391870783047, 13.340298224089668, 7.414841720329198, 4.666325209906814, 3.5904366834219448, 2.2929934268911074, 2.1472316679168557, 3.419695878608058, 1.4381461140150031, 1.4381249770673938, 1.4381986386179022, 1.438235742487646, 1.4383045474740541, 1.4386908695808907, 1.4383433176195348, 1.438507165397605, 1.4384309698515243, 1.4385503637184403, 1.4380640212008273, 1.4380700395903174, 1.4381550043782008, 1.4381485655273585, 1.4386463234164417, 1.4381593830237371, 1.4380691946351392, 1.438083193368739, 1.4380617111855294, 1.4381364872784967, 1.4380645301665207, 1.4381705167140455, 1.4385671593265017, 1.4381811947177183, 1.4388993757980406, 1.4384222767437578, 1.440007992076163, 1.43928560318411, 1.4383446391800605, 1.438673961212277, 1.4409611433640424, 1.4388512332793737, 1.438325646885302, 11.75523717959161, 62.94036215216824, 7.545355497299413, 4.7787847619333315, 2.6736547031563616, 1.438138651053903, 1.4381786172358098, 1.4382057123757774, 1.4382060346931542, 1.4381571529119193, 1.438135046733719, 1.4381479572249518, 1.4381608098693122, 1.4382194730795366, 1.4388550077805962, 1.4383606207898305, 1.4381455327256507, 1.4380786506593444, 1.4381096694502973, 1.4385087468592432, 1.4381067135049985, 1.438073076035413, 1.438073076035413, 1.4381698664282248, 1.4380759434410804, 1.4392511213612864, 1.438077635171953, 1.4381272912162992, 1.4381785635968596, 1.438139139028951, 1.4381734585882289, 1.4384658657368599, 1.4409611433640424, 1.4385479295166854, 1.4388512332793737, 1.439008835481906, 1.440007992076163, 28.369927271745965, 8.22422127268613, 4.117042361112518, 1.4386463234164417, 1.4385126890164892, 1.4385449612419872, 1.4388993757980406, 1.438083218320604, 1.43814254590572, 1.438150434275586, 1.4380985013936272, 1.4380682925361818, 1.4381593830237371, 1.4380654419274856, 1.4380654419274856, 1.4381785635968596, 1.4381138748900826, 1.438124079753167, 1.438358196411411, 1.438230855269963, 1.438068802936449, 1.438068802936449, 1.438068802936449, 1.4380617376385343, 1.4380617376385343, 1.4380735623656036, 1.4380735623656036, 1.4380735623656036, 1.438070297999824, 1.438073775833555, 1.4382243785483182, 1.4382991792314097, 1.438772170082097, 1.438315365258959, 1.4383849073366, 1.4382548785397709, 1.4409611433640424, 1.4385478055178584, 1.438239522399463, 1.4385299664297069, 1.43928560318411, 1.4388550077805962], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.1885, -1.3735, -1.7549, -2.223, -3.2623, -4.0628, -4.3376, -3.3049, -4.8265, -5.2311, -5.5082, -5.9976, -6.2956, -6.674, -6.7904, -4.5028, -7.0279, -7.3967, -7.6573, -8.1321, -8.2448, -8.4064, -8.9024, -9.2254, -9.6489, -11.559, -11.5617, -11.5629, -11.5631, -11.5632, -11.5631, -0.9852, -1.9138, -2.0517, -2.6271, -2.9161, -3.9649, -3.9832, -4.3358, -4.5431, -4.6711, -4.742, -4.9286, -5.1696, -5.3131, -5.3261, -6.2993, -6.2993, -6.4318, -7.4094, -7.4094, -7.5539, -7.5539, -7.554, -7.2042, -5.4684, -9.7288, -9.7286, -9.7274, -9.7289, -9.7289, -9.7284, -8.9501, -0.2559, -3.9859, -3.3207, -9.2879, -9.2892, -9.2898, -9.2893, -9.2899, -9.2903, -9.2897, -9.2905, -9.2898, -9.2903, -9.2903, -9.2902, -9.2906, -9.2903, -9.2905, -9.2905, -9.2886, -9.2906, -9.2904, -9.2906, -9.2906, -9.2907, -9.2906, -9.2908, -9.2907, -9.2907, -9.2906, -9.2903, -9.2907, -9.2903, -9.2906, -9.2905, -9.2906, -9.2906, -8.8171, -1.1731, -1.3975, -2.3263, -2.8947, -3.2845, -3.7428, -3.8238, -4.2833, -5.175, -5.4106, -5.6736, -5.6942, -6.1655, -7.3893, -7.3893, -6.9626, -5.1234, -9.3091, -9.3097, -9.3095, -9.3097, -9.3097, -9.3096, -9.3097, -9.3097, -9.31, -9.31, -9.3096, -9.31, -9.3099, -9.3096, -9.3096, -9.3088, -9.3095, -0.8033, -1.9851, -3.1306, -3.6517, -4.3704, -4.7875, -4.1704, -5.6432, -6.6689, -8.7112, -8.7121, -8.712, -8.7122, -8.7122, -8.712, -8.7124, -8.7125, -8.7125, -8.7125, -8.7125, -8.7124, -8.712, -8.7124, -8.7125, -8.7125, -8.7126, -8.7125, -8.7125, -8.7125, -8.7126, -8.7121, -8.7122, -8.7122, -8.7114, -8.7125, -8.7125, -8.7124, -8.7124, -8.7124, -1.5103, -2.3835, -2.6031, -2.7603, -3.1747, -3.2048, -3.2283, -3.2599, -4.3137, -4.3479, -4.5051, -2.8269, -4.5273, -4.6845, -4.8072, -4.9209, -5.1385, -5.2226, -5.8333, -6.0943, -6.7757, -6.7757, -6.7907, -8.9508, -8.951, -8.9507, -8.9514, -8.9512, -8.9519, -8.9519, -8.9518, -8.9512, -8.9516, -8.9513, -8.9514, -1.0093, -3.2206, -3.6686, -3.8959, -4.1505, -4.684, -1.1905, -5.6087, -5.7448, -6.4866, -9.0664, -9.0673, -9.0695, -9.0695, -9.0702, -9.0703, -9.0702, -9.0701, -9.0703, -9.0705, -9.0705, -9.0705, -9.0705, -9.0704, -9.0706, -9.0707, -9.0707, -9.0701, -9.0706, -9.0707, -9.0702, -9.0703, -9.0702, -9.0698, -9.0705, -9.0705, -1.796, -2.0206, -2.3071, -2.418, -3.6477, -3.813, -4.0572, -4.1086, -4.5588, -5.2611, -5.3375, -5.549, -5.6459, -6.0811, -6.0811, -6.0811, -6.5687, -6.7014, -6.7014, -6.7017, -6.702, -2.3913, -6.7012, -8.7419, -8.7446, -8.7446, -8.7446, -8.7446, -8.7446, -8.7446, -8.7444, -5.2405, -8.7445, -8.7445, -8.7443, -8.7445, -8.7445, -0.7162, -2.2912, -2.3914, -3.276, -6.113, -6.113, -6.8127, -4.4167, -8.8537, -8.8553, -8.8551, -8.8558, -8.8557, -8.8559, -8.856, -8.856, -8.8559, -8.856, -8.8559, -8.8562, -8.8562, -8.8563, -8.8563, -8.8563, -8.8563, -8.8564, -8.8564, -8.8563, -8.8563, -8.8563, -8.8546, -8.8558, -8.8559, -8.856, -8.8562, -8.8557, -8.8562, -8.8562, -8.8562, -8.8562, -8.8562, -1.6258, -1.7641, -1.9188, -2.8122, -3.5503, -3.8696, -4.0164, -4.2335, -4.3158, -3.3901, -5.041, -5.299, -6.619, -6.6195, -6.7523, -6.2539, -8.7948, -8.7948, -8.7948, -8.7948, -8.7948, -8.7947, -8.7951, -8.795, -8.7953, -8.7953, -8.7953, -8.7956, -8.7954, -8.7955, -8.7954, -8.7953, -8.7947, -1.332, -2.6588, -2.8026, -2.9848, -3.0765, -3.1165, -4.0464, -4.4946, -4.5376, -5.3564, -5.3911, -5.5196, -5.5256, -6.3977, -6.3977, -6.3977, -6.3983, -6.5192, -6.5192, -6.2655, -8.4411, -8.4411, -8.4412, -8.4412, -8.4406, -8.4412, -8.4413, -8.441, -8.4413, -8.4408, -8.441, -8.4409, -8.4406, -8.4411, -8.441, -8.4406, -8.441, -8.441, -1.4607, -1.4685, -2.9256, -3.0362, -3.2337, -3.5992, -3.6438, -4.6525, -4.6918, -6.1213, -6.6173, -6.6173, -8.6598, -8.6598, -8.6598, -8.6598, -8.6598, -8.659, -8.658, -8.66, -8.6601, -8.6601, -8.6604, -8.6605, -8.6605, -8.6605, -8.6606, -8.6606, -8.6599, -8.6593, -8.6603, -8.6602, -2.0586, -2.2497, -2.5315, -2.7471, -3.4084, -3.7973, -4.0498, -4.1291, -4.153, -4.3023, -4.6281, -5.38, -5.4465, -5.4551, -5.5201, -5.5201, -5.6495, -5.8154, -5.8154, -6.1366, -6.2698, -6.2699, -5.8211, -5.0857, -8.3115, -8.3124, -8.3126, -8.3126, -8.3126, -8.3126, -8.3121, -8.3115, -8.3126, -1.4726, -2.0025, -2.6424, -3.5592, -3.9458, -3.9505, -4.625, -5.9332, -6.0775, -6.0775, -8.2535, -8.2538, -8.2539, -8.254, -8.254, -8.254, -8.254, -8.2541, -8.2541, -8.2541, -8.2541, -8.2541, -8.254, -8.2541, -8.2541, -8.2541, -8.2541, -8.2541, -8.2539, -8.254, -8.2536, -8.253, -8.2539, -8.254, -8.254, -8.254, -8.254, -2.136, -2.2887, -2.6972, -2.7155, -3.0546, -3.2469, -3.9614, -3.9931, -4.7285, -5.0127, -5.036, -5.3369, -5.5887, -5.5887, -5.5887, -6.0762, -6.2091, -6.2094, -8.2517, -8.2524, -8.2524, -8.2524, -8.2522, -8.2524, -8.2522, -8.2526, -8.2526, -8.2526, -8.2525, -8.2526, -8.2521, -8.2513, -8.2525, -8.2524, -8.2524, -8.2524, -1.8047, -2.0288, -2.783, -3.1116, -4.1924, -4.6247, -4.9584, -5.0793, -5.3406, -5.9352, -5.9352, -6.213, -5.6113, -2.7283, -8.2553, -8.2557, -8.256, -8.256, -8.2564, -8.2564, -8.2564, -8.2564, -8.2564, -8.2565, -8.2564, -8.2565, -8.2565, -8.2565, -8.2565, -8.2565, -8.2564, -8.2565, -8.2564, -8.2564, -8.2564, -8.2564, -8.2562, -8.2558, -8.2563, -8.2562, -8.2563, -8.2564, -8.2564, -8.2562, -8.2564, -8.2563, -1.3123, -3.0573, -3.1242, -4.2868, -4.614, -2.6601, -5.8038, -8.1325, -8.1323, -8.1327, -8.1328, -8.1328, -8.1329, -8.1328, -8.1329, -8.1325, -8.1329, -8.1329, -8.133, -8.133, -8.133, -8.133, -8.133, -8.133, -8.1329, -8.1331, -8.1331, -8.1331, -8.1331, -8.1331, -8.1328, -8.1325, -8.1329, -8.133, -8.1327, -8.1321, -8.1329, -8.133, -8.1329, -8.1329, -1.2451, -2.6997, -2.7809, -3.4653, -4.0738, -4.4711, -5.3585, -5.5335, -5.1754, -8.1967, -8.1967, -8.1967, -8.197, -8.1969, -8.1967, -8.197, -8.1969, -8.197, -8.1969, -8.1973, -8.1973, -8.1972, -8.1972, -8.1969, -8.1972, -8.1973, -8.1973, -8.1973, -8.1973, -8.1973, -8.1972, -8.197, -8.1972, -8.1969, -8.1971, -8.1965, -8.1968, -8.1972, -8.1971, -8.1967, -8.1971, -8.1972, -2.8275, -1.1578, -3.3483, -3.9444, -4.9126, -8.0945, -8.0945, -8.0945, -8.0945, -8.0947, -8.0947, -8.0948, -8.0948, -8.0948, -8.0944, -8.0948, -8.095, -8.095, -8.095, -8.0948, -8.0951, -8.0951, -8.0951, -8.0951, -8.0951, -8.0943, -8.0951, -8.0951, -8.0951, -8.0951, -8.0951, -8.095, -8.0945, -8.095, -8.095, -8.0951, -8.0951, -1.4711, -2.8448, -3.7644, -7.8965, -7.8967, -7.8967, -7.8967, -7.8973, -7.8972, -7.8972, -7.8973, -7.8974, -7.8973, -7.8974, -7.8974, -7.8973, -7.8974, -7.8974, -7.8972, -7.8973, -7.8975, -7.8975, -7.8975, -7.8975, -7.8975, -7.8975, -7.8975, -7.8975, -7.8975, -7.8975, -7.8974, -7.8974, -7.8972, -7.8974, -7.8974, -7.8974, -7.8966, -7.8973, -7.8974, -7.8974, -7.8972, -7.8974], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6747, 0.6747, 0.6744, 0.6739, 0.6715, 0.667, 0.6644, 0.6632, 0.6576, 0.649, 0.6407, 0.6195, 0.6009, 0.5685, 0.5561, 0.5378, 0.5264, 0.4666, 0.412, 0.2804, 0.2423, 0.1824, -0.0406, -0.2186, -0.4899, -2.0927, -2.0948, -2.0954, -2.0954, -2.0955, -2.0956, 2.5587, 2.5548, 2.5539, 2.5483, 2.544, 2.5128, 2.5119, 2.4918, 2.4764, 2.4654, 2.4587, 2.4389, 2.408, 2.3864, 2.3843, 2.1476, 2.1476, 2.1008, 1.6234, 1.6234, 1.533, 1.533, 1.5329, 1.5152, 0.574, -0.2609, -0.261, -0.2611, -0.2612, -0.2613, -0.2614, -2.0668, 2.9747, 2.8974, 2.5954, 0.1791, 0.1784, 0.1781, 0.1781, 0.1779, 0.1778, 0.1778, 0.1777, 0.1777, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1776, 0.1775, 0.1775, 0.1774, 0.1774, 0.1774, 0.1774, 0.1774, 0.1774, 0.1774, 0.1774, 0.1774, 0.1772, 0.1772, 0.1773, -4.8491, 3.0057, 3.0045, 2.9954, 2.9841, 2.9718, 2.9499, 2.945, 2.9087, 2.7783, 2.7248, 2.6527, 2.6464, 2.4778, 1.7891, 1.7891, 1.7759, 1.5014, 0.1588, 0.1584, 0.1584, 0.1584, 0.1584, 0.1584, 0.1582, 0.1581, 0.1581, 0.1581, 0.1581, 0.1581, 0.1581, 0.158, 0.1579, 0.1575, 0.1575, 3.3918, 3.3811, 3.3487, 3.3172, 3.24, 3.1677, 3.1256, 2.9234, 2.4079, 0.7567, 0.7561, 0.756, 0.756, 0.756, 0.7559, 0.7558, 0.7558, 0.7558, 0.7558, 0.7558, 0.7557, 0.7557, 0.7557, 0.7557, 0.7557, 0.7556, 0.7556, 0.7556, 0.7556, 0.7556, 0.7555, 0.7555, 0.7555, 0.7548, 0.7556, 0.7555, 0.7553, 0.7553, 0.7546, 3.387, 3.3735, 3.3678, 3.363, 3.346, 3.3445, 3.3433, 3.3416, 3.246, 3.2412, 3.2169, 3.2155, 3.2132, 3.1851, 3.1605, 3.1355, 3.081, 3.0576, 2.8407, 2.721, 2.329, 2.329, 1.9287, 0.5171, 0.5171, 0.517, 0.5168, 0.5167, 0.5163, 0.5163, 0.5163, 0.5162, 0.5163, 0.5156, 0.5149, 3.3936, 3.346, 3.3169, 3.2969, 3.2689, 3.1861, 3.1601, 2.9296, 2.8764, 2.5062, 0.4005, 0.4001, 0.3982, 0.3981, 0.3978, 0.3978, 0.3977, 0.3977, 0.3977, 0.3977, 0.3976, 0.3976, 0.3976, 0.3976, 0.3975, 0.3975, 0.3975, 0.3975, 0.3975, 0.3975, 0.3975, 0.3974, 0.3973, 0.3964, 0.3973, 0.3973, 3.5164, 3.5127, 3.5066, 3.5038, 3.4403, 3.4248, 3.3972, 3.3906, 3.3187, 3.1405, 3.1152, 3.0381, 2.8399, 2.7963, 2.7963, 2.7963, 2.5133, 2.4266, 2.4266, 2.4264, 2.4262, 1.9593, 1.9284, 0.7243, 0.7236, 0.7236, 0.7236, 0.7236, 0.7236, 0.7236, 0.7236, -1.2725, 0.7235, 0.7235, 0.7226, 0.723, 0.7229, 3.529, 3.5096, 3.5071, 3.4699, 2.7773, 2.7773, 2.3469, 1.2727, 0.6139, 0.6127, 0.6126, 0.6122, 0.6122, 0.6122, 0.6122, 0.6122, 0.6122, 0.6122, 0.612, 0.612, 0.612, 0.612, 0.612, 0.6119, 0.6119, 0.6119, 0.6119, 0.6119, 0.6119, 0.6119, 0.6117, 0.6117, 0.6116, 0.6116, 0.6118, 0.6112, 0.6118, 0.6117, 0.6116, 0.6115, 0.6116, 3.5402, 3.5383, 3.5359, 3.5116, 3.4681, 3.4379, 3.4209, 3.3913, 3.3786, 3.2346, 3.2211, 3.1411, 2.4856, 2.4853, 2.3961, 2.3482, 0.6733, 0.6733, 0.6732, 0.6732, 0.6731, 0.673, 0.673, 0.6729, 0.6729, 0.6728, 0.6728, 0.6726, 0.6726, 0.6726, 0.6726, 0.6725, 0.6715, 4.0003, 3.9592, 3.9507, 3.9382, 3.9311, 3.9278, 3.8064, 3.705, 3.6933, 3.3937, 3.3775, 3.3148, 3.3118, 2.7791, 2.7791, 2.7791, 2.7787, 2.6915, 2.6915, 2.2203, 1.0271, 1.027, 1.027, 1.027, 1.027, 1.0269, 1.0269, 1.0269, 1.0269, 1.0269, 1.0269, 1.0268, 1.0263, 1.0268, 1.0267, 1.0256, 1.0265, 1.0267, 4.0009, 4.0007, 3.9444, 3.9361, 3.919, 3.878, 3.8721, 3.6591, 3.6471, 2.9613, 2.6113, 2.6113, 0.8085, 0.8085, 0.8085, 0.8085, 0.8084, 0.8084, 0.8082, 0.8082, 0.808, 0.8079, 0.8077, 0.8077, 0.8077, 0.8077, 0.8076, 0.8076, 0.8076, 0.8076, 0.8075, 0.8075, 4.1607, 4.153, 4.1386, 4.1248, 4.0603, 4.0009, 3.9507, 3.9327, 3.9271, 3.8895, 3.7921, 3.4742, 3.4393, 3.4348, 3.3995, 3.3995, 3.3263, 3.2264, 3.2264, 3.0149, 2.9207, 2.9206, 2.9174, 2.2103, 1.156, 1.1558, 1.1556, 1.1556, 1.1556, 1.1556, 1.1555, 1.1547, 1.1555, 4.2989, 4.2825, 4.2476, 4.1443, 4.0699, 4.0688, 3.8733, 3.1914, 3.0914, 3.0914, 1.2145, 1.2143, 1.2143, 1.2142, 1.2142, 1.2142, 1.2142, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.2141, 1.214, 1.214, 1.2133, 1.2136, 1.2137, 1.2138, 1.2139, 1.2134, 4.3109, 4.3032, 4.2764, 4.2749, 4.243, 4.2201, 4.0936, 4.0861, 3.8557, 3.7335, 3.7226, 3.5697, 3.4245, 3.4245, 3.4245, 3.1015, 3.0046, 3.0044, 1.2162, 1.2158, 1.2158, 1.2158, 1.2157, 1.2157, 1.2157, 1.2157, 1.2157, 1.2156, 1.2156, 1.2156, 1.2156, 1.2149, 1.2156, 1.2153, 1.2152, 1.2152, 4.4142, 4.4049, 4.3542, 4.3185, 4.1004, 3.9516, 3.8067, 3.7474, 3.6067, 3.2258, 3.2258, 3.0218, 3.0184, 2.3123, 1.2129, 1.2125, 1.2122, 1.212, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2118, 1.2117, 1.2116, 1.2111, 1.2116, 1.2115, 1.2116, 1.2117, 1.2117, 1.2112, 1.2117, 1.2113, 4.4656, 4.3586, 4.3501, 4.0982, 3.98, 3.2561, 2.8259, 1.3357, 1.3356, 1.3355, 1.3354, 1.3353, 1.3353, 1.3353, 1.3353, 1.3353, 1.3353, 1.3353, 1.3353, 1.3353, 1.3352, 1.3352, 1.3352, 1.3352, 1.3352, 1.3352, 1.3352, 1.3352, 1.3352, 1.3351, 1.3351, 1.3351, 1.3351, 1.3351, 1.335, 1.3342, 1.3349, 1.335, 1.3348, 1.334, 4.5449, 4.468, 4.4599, 4.3627, 4.2174, 4.0822, 3.6432, 3.5339, 3.4266, 1.2715, 1.2715, 1.2714, 1.2712, 1.2711, 1.2711, 1.2711, 1.2711, 1.271, 1.271, 1.271, 1.271, 1.271, 1.271, 1.271, 1.271, 1.271, 1.271, 1.2709, 1.2709, 1.2709, 1.2709, 1.2709, 1.2709, 1.2708, 1.2709, 1.2705, 1.2706, 1.2709, 1.2707, 1.2696, 1.2706, 1.2709, 4.5398, 4.5316, 4.4623, 4.323, 3.9355, 1.3737, 1.3737, 1.3737, 1.3737, 1.3735, 1.3735, 1.3734, 1.3734, 1.3734, 1.3733, 1.3732, 1.3732, 1.3732, 1.3732, 1.3732, 1.3732, 1.3732, 1.3732, 1.3731, 1.3731, 1.3731, 1.3731, 1.3731, 1.3731, 1.3731, 1.3731, 1.373, 1.3717, 1.3729, 1.3727, 1.3725, 1.3719, 5.0151, 4.8797, 4.652, 1.5713, 1.5712, 1.5712, 1.571, 1.571, 1.571, 1.571, 1.5709, 1.5709, 1.5709, 1.5709, 1.5709, 1.5709, 1.5709, 1.5709, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5708, 1.5707, 1.5706, 1.5707, 1.5707, 1.5707, 1.5697, 1.5706, 1.5707, 1.5706, 1.5702, 1.5704]}, \"token.table\": {\"Topic\": [8, 1, 14, 11, 13, 4, 4, 10, 14, 15, 8, 6, 12, 2, 15, 4, 15, 16, 1, 15, 8, 1, 13, 2, 19, 9, 8, 16, 6, 13, 2, 4, 15, 9, 4, 5, 13, 2, 5, 20, 10, 1, 1, 10, 12, 16, 8, 12, 14, 14, 1, 1, 18, 11, 12, 13, 8, 19, 13, 6, 11, 11, 11, 14, 4, 10, 5, 13, 13, 15, 2, 2, 11, 13, 13, 7, 8, 10, 7, 6, 7, 2, 1, 8, 15, 2, 8, 9, 17, 4, 4, 3, 18, 7, 2, 6, 20, 10, 2, 6, 6, 1, 18, 5, 1, 17, 15, 2, 13, 13, 1, 8, 9, 6, 7, 4, 7, 8, 8, 4, 10, 16, 16, 16, 11, 18, 12, 13, 8, 9, 19, 10, 2, 11, 8, 16, 17, 8, 11, 2, 6, 6, 2, 8, 9, 12, 8, 18, 1, 2, 13, 5, 7, 10, 10, 13, 3, 17, 15, 5, 4, 2, 5, 4, 1, 6, 13, 1, 1, 18, 2, 17, 15, 6, 10, 14, 1, 17, 19, 1, 6, 20, 11, 8, 6, 7, 11, 1, 6, 6, 4, 15, 14, 2, 3, 16, 1, 6, 1, 16, 6, 12, 1, 8, 19, 1, 6, 8, 9, 8, 5, 18, 8, 11, 11, 18, 6, 2, 15, 11, 15, 6, 13, 17, 11, 5, 7, 14, 16, 16, 2, 1, 13, 14, 4, 15, 2, 11, 4, 4, 7, 6, 2, 9, 16, 16, 2, 10, 2, 12, 8, 1, 10, 11, 13, 13, 10, 6, 2, 8, 10, 18, 12, 15, 1, 13, 15, 12, 4, 13, 13, 14, 10, 13, 11], \"Freq\": [0.4726067139323999, 0.9989965871762502, 0.8164893626293196, 0.3700190756892107, 0.7314123529215876, 0.9961585318527284, 0.9792297526557912, 0.8804089368666106, 0.8334620270852415, 0.44117876489905933, 0.8353458533816891, 0.9493674081394006, 0.8923433801002829, 0.9982835851911976, 0.3965588007905163, 0.609497611920549, 0.9337374456129187, 0.9058316445635671, 0.379187476894548, 0.8727875278646857, 0.9715404485110374, 0.9011078322287672, 0.40174083817189205, 0.8391921792726637, 0.8506846648199582, 0.5107236024014142, 0.9786107554070131, 0.41300456475354075, 0.4834486788682835, 0.9717308322351066, 0.4498841210954397, 0.7335252146856152, 0.44117876489905933, 0.9597259937560536, 0.520389242878839, 0.9947795341835861, 0.9329859798634117, 0.474891044544529, 0.47015258146081446, 0.8511444145171589, 0.48338134440637365, 0.9833857739021048, 0.43831079055397776, 0.9884346087636972, 0.4728419313495165, 0.5700096787008905, 0.3851346274677454, 0.6561816368272098, 0.9831514633889239, 0.8135198367113854, 0.9994491771179891, 0.990739002864943, 0.9839155947998696, 0.3689324376558852, 0.9816850899299863, 0.3899495608150314, 0.9822193626051119, 0.795191161257741, 0.3883880848530936, 0.8250170366852926, 0.519603964563425, 0.6908338072739959, 0.782144437099694, 0.515452615571251, 0.9281244248527108, 0.6244279394832153, 0.7922063989799002, 0.15844127979598005, 0.9402803431690606, 0.8460787239997669, 0.8399294608071941, 0.9362732498677303, 0.9894564766105862, 0.6940641473406253, 0.5267133514172354, 0.7872798621128502, 0.2082750957970503, 0.7462078557761623, 0.5487611746645674, 0.361926328866046, 0.9549699239306296, 0.9853482418816827, 0.9642433464099227, 0.7555756124911124, 0.9181573943704873, 0.47492139926501786, 0.4948687282326417, 0.3901273018420385, 0.5801772128117392, 0.520389242878839, 0.665849882312932, 0.9975376250325472, 0.43611114985001187, 0.9287755949119058, 0.32886019304577496, 0.32886019304577496, 0.9517119921167265, 0.5050572210851512, 0.1356898949714957, 0.8367543523242235, 0.9598046384879086, 0.7258289747979726, 0.6429041837098854, 0.5644949336868664, 0.9920168493918972, 0.9720717497952479, 0.6839896702988059, 0.4498841210954397, 0.5267216756800884, 0.3762759578403411, 0.5213182786010564, 0.9808548812250194, 0.9768481243244999, 0.4834486788682835, 0.43225055921110067, 0.9522631277255457, 0.9919027412706872, 0.7179934278633135, 0.49482825824828075, 0.2024281047195892, 0.7287411769905211, 0.6884363959148695, 0.9712567527625807, 0.9698840672655582, 0.5196885862731285, 0.899530115326104, 0.9312797729825152, 0.4539429766564796, 0.8968523516950675, 0.11121639216305107, 0.8738430812811155, 0.9123751828553915, 0.8508826934601891, 0.923853947011593, 0.30062045069516347, 0.30062045069516347, 0.30062045069516347, 0.5207287459147321, 0.26036437295736603, 0.47489334600950717, 0.9930818962353878, 0.8472255329974749, 0.9435750611911137, 0.5761841119520582, 0.3901273018420385, 0.9169835815064414, 0.8501938553569669, 0.8091878729588873, 0.5104056343753559, 0.9422057832849585, 0.4539429766564796, 0.8678692017798887, 0.5961934764432543, 0.9002055664107745, 0.8814566007316069, 0.4249294064312186, 0.6776762737544785, 0.2989748266563876, 0.6755704969557443, 0.989025555580648, 0.7642932809539185, 0.7512757666970494, 0.7657112684177385, 0.9351390387850745, 0.9996804221773654, 0.9385707300778576, 0.7853581138536765, 0.9805016584305014, 0.6866200903514822, 0.5570353069403959, 0.5456022298817849, 0.7060753673178353, 0.9402819925273718, 0.6358663749259509, 0.8258492603044169, 0.9500787354793004, 0.9164861796364001, 0.8930682648867478, 0.627774664365989, 0.9966912150262016, 0.9685540123825048, 0.7286784387589668, 0.9207978584234201, 0.4949242105102952, 0.8434834159108358, 0.8439763650456182, 0.8294407672945996, 0.9559198364597897, 0.8649470097029885, 0.9486643614197501, 0.9900386245512794, 0.845977976276104, 0.9511541027799026, 0.9602283125848281, 0.9437319629220493, 0.511413911794938, 0.9031903334552249, 0.8495368197931781, 0.8719371596735117, 0.11625828795646823, 0.849035108003888, 0.6743252160002553, 0.9887840161075538, 0.008524000138858222, 0.37401987579752094, 0.5771846512609292, 0.7979647266003005, 0.3851346274677454, 0.9791361857641567, 0.3851346274677454, 0.9138913438778207, 0.465715933190457, 0.8735709400900122, 0.519605451878269, 0.6781811058003545, 0.9058354839063208, 0.6285083366336613, 0.8301418639844432, 0.5200119080697704, 0.8070405962672281, 0.6934357545886758, 0.9562673938912024, 0.8011745639936478, 0.8520838974091431, 0.519603964563425, 0.9451170729428895, 0.9291446785011177, 0.49311090139839153, 0.8785999181487976, 0.36606717965910274, 0.9882951625434321, 0.9987231359185967, 0.9320030536993964, 0.5271921000112495, 0.6754898298401181, 0.9488350280854442, 0.994376416616731, 0.8905028745114116, 0.9533626864633656, 0.9953366168786553, 0.8962251296649933, 0.7753318150814005, 0.9012555986600514, 0.993388003262943, 0.643954794491021, 0.511413911794938, 0.7512757666970494, 0.9799881653810915, 0.8779810921244668, 0.8882822554455676, 0.9007471866916864, 0.8205361490908865, 0.4834530609157929, 0.9650393778177436, 0.8474254006808318, 0.4017266994197976, 0.9587644374963635, 0.9689453389659997, 0.9936639962063506, 0.49482825824828075, 0.29242366441282397, 0.29242366441282397, 0.9868492188960977, 0.5745188784738933, 0.8381415704766446, 0.7761015006698796, 0.44117876489905933, 0.8545689890639222, 0.3351993787475176, 0.3351993787475176, 0.6814983347779089, 0.515452615571251, 0.9818444771485335, 0.506600925417162, 0.927402553444861], \"Term\": [\"abandon\", \"accuse\", \"admit\", \"affair\", \"agent\", \"allege\", \"allow\", \"annual\", \"answer\", \"anti\", \"approval\", \"approve\", \"area\", \"arrest\", \"as\", \"assgned\", \"assign\", \"assignment\", \"assignmnet\", \"assist\", \"attempt\", \"attend\", \"attire\", \"attitude\", \"authorization\", \"azccuse\", \"back\", \"backup\", \"baker\", \"become\", \"blachard\", \"book\", \"breach\", \"break\", \"burr\", \"call\", \"camera\", \"cbm\", \"cctv\", \"cell_phone\", \"chapman\", \"check\", \"chief\", \"child\", \"class\", \"clean\", \"cmt\", \"co_worker\", \"come\", \"communication\", \"complainant\", \"complaint\", \"complete\", \"completion\", \"conduct\", \"confrontational\", \"contact\", \"control\", \"cooperate\", \"correctly\", \"course\", \"create\", \"daily\", \"datum\", \"deliver\", \"deny\", \"deputy\", \"deputy\", \"detail\", \"disciplinary\", \"display\", \"disrespectful\", \"document\", \"dorm\", \"dugar\", \"duty\", \"duty\", \"early\", \"effect\", \"effort\", \"emergency\", \"employee\", \"end\", \"engage_verbal_altercation\", \"enter\", \"evacuatin\", \"extend\", \"extended\", \"extended_lunch_break\", \"faceboook\", \"facility\", \"fail\", \"fake\", \"family\", \"fill\", \"fill\", \"find\", \"flood\", \"follow\", \"follow\", \"form\", \"former\", \"frame\", \"frazi\", \"give\", \"go\", \"granddaughter\", \"harassign\", \"harrison\", \"hat\", \"history\", \"home\", \"hour\", \"housing\", \"ihop\", \"inappropriate\", \"incident\", \"incorrect\", \"info\", \"inform\", \"inform\", \"inspection\", \"instruct\", \"instruction\", \"internal\", \"item\", \"language\", \"laptop\", \"late\", \"leave\", \"leave\", \"lie\", \"lieutenant\", \"log\", \"lunch\", \"lunch\", \"lunch\", \"lunch_break\", \"lunch_break\", \"major\", \"make\", \"mandatory\", \"manner\", \"medication\", \"min\", \"minute\", \"minute_late\", \"miss\", \"misuse\", \"money\", \"movie\", \"multiple\", \"narcotic\", \"need\", \"neighborhood\", \"nofty\", \"notify\", \"notify\", \"numerous\", \"observe\", \"occasion\", \"oder\", \"offender\", \"office\", \"officer\", \"only\", \"opso\", \"order\", \"own\", \"packet\", \"paper\", \"partner\", \"party\", \"patrol\", \"pay_detail\", \"perform\", \"personal\", \"physical_altercation\", \"pod\", \"police\", \"policy\", \"possession\", \"post\", \"pregancy\", \"prepare\", \"present\", \"previous\", \"prior\", \"procedure\", \"proper\", \"properly\", \"protection\", \"provide\", \"put\", \"rank\", \"ready\", \"receive\", \"recruit\", \"refuse\", \"refuse\", \"relate\", \"remain\", \"report\", \"report\", \"repot\", \"reprimand\", \"require\", \"retune\", \"return\", \"reynold\", \"roll\", \"rporte\", \"schedule\", \"security\", \"security_patrol\", \"send\", \"sercurity\", \"serve\", \"shakedown\", \"sheet\", \"shift\", \"show\", \"sick\", \"sign\", \"signin\", \"sit\", \"sleep\", \"smoke\", \"so\", \"solution\", \"speak\", \"state\", \"station\", \"statistic\", \"stay\", \"store\", \"subject\", \"submit\", \"subpoena\", \"supervisor\", \"supervisory\", \"sure\", \"system\", \"take\", \"target\", \"tdc\", \"tiger\", \"time\", \"timely_manner\", \"tone\", \"tour\", \"training\", \"treport\", \"turn\", \"unable\", \"unapproved\", \"unauthorized\", \"unit\", \"unprofessional\", \"unsuccessful\", \"uof\", \"uof\", \"use\", \"utilize\", \"verbal\", \"verbally\", \"virus\", \"vulgar\", \"watch\", \"watch\", \"wear\", \"weekly\", \"work\", \"wrrite\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 8, 3, 12, 11, 19, 14, 9, 18, 13, 7, 15, 10, 2, 17, 5, 6, 4, 20, 16]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1548021740535992649680788504\", ldavis_el1548021740535992649680788504_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1548021740535992649680788504\", ldavis_el1548021740535992649680788504_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1548021740535992649680788504\", ldavis_el1548021740535992649680788504_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.483596 -0.285522       1        1  50.904663\n",
       "7     -0.439882  0.091966       2        1   7.721138\n",
       "2      0.028766 -0.410485       3        1   5.096963\n",
       "11    -0.167599 -0.337273       4        1   4.926976\n",
       "10     0.089072  0.351107       5        1   3.348896\n",
       "18    -0.125425  0.350897       6        1   3.347902\n",
       "13    -0.277616  0.208132       7        1   3.338645\n",
       "8     -0.223776 -0.055483       8        1   2.926921\n",
       "17     0.203108 -0.293970       9        1   2.918521\n",
       "12     0.364733 -0.103772      10        1   2.863635\n",
       "6      0.185493 -0.137099      11        1   1.803161\n",
       "14     0.297069  0.217510      12        1   1.798012\n",
       "9     -0.057631 -0.070919      13        1   1.501952\n",
       "1     -0.037484  0.057508      14        1   1.326146\n",
       "16    -0.024950  0.166986      15        1   1.279587\n",
       "4      0.112487  0.188636      16        1   1.165287\n",
       "5      0.063591 -0.080401      17        1   1.122345\n",
       "3      0.242080  0.026643      18        1   1.036324\n",
       "19     0.168268  0.078840      19        1   0.941857\n",
       "15     0.083291  0.036699      20        1   0.631071, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "32          fail   735.000000   735.000000  Default  30.0000  30.0000\n",
       "7        officer  2887.000000  2887.000000  Default  29.0000  29.0000\n",
       "315  complainant  2400.000000  2400.000000  Default  28.0000  28.0000\n",
       "252       arrest   537.000000   537.000000  Default  27.0000  27.0000\n",
       "45        accuse  1639.000000  1639.000000  Default  26.0000  26.0000\n",
       "..           ...          ...          ...      ...      ...      ...\n",
       "287          ask     0.043662     1.438548  Topic20  -7.8973   1.5706\n",
       "855        drive     0.043658     1.438240  Topic20  -7.8974   1.5707\n",
       "550        front     0.043660     1.438530  Topic20  -7.8974   1.5706\n",
       "373      neglect     0.043666     1.439286  Topic20  -7.8972   1.5702\n",
       "416         also     0.043661     1.438855  Topic20  -7.8974   1.5704\n",
       "\n",
       "[769 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "179       8  0.472607  abandon\n",
       "45        1  0.998997   accuse\n",
       "238      14  0.816489    admit\n",
       "146      11  0.370019   affair\n",
       "186      13  0.731412    agent\n",
       "...     ...       ...      ...\n",
       "117      13  0.681498     wear\n",
       "195      14  0.515453   weekly\n",
       "27       10  0.981844     work\n",
       "191      13  0.506601   wrrite\n",
       "145      11  0.927403     year\n",
       "\n",
       "[275 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 8, 3, 12, 11, 19, 14, 9, 18, 13, 7, 15, 10, 2, 17, 5, 6, 4, 20, 16])"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(gensim_model, train_corpus, id2word, mds=\"mmds\", R=30)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6c8f846148a3e4d140e6ddf63c190cff559dcf260a4a21539f0978f2b58638c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
